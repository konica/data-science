{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf5ec2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os   \n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b7f17bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BxP8QFD7MQQ4qKih4NIKtvsYXITkb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--84b3c056-1a80-4110-9e16-984b1ba0928f-0', usage_metadata={'input_tokens': 11, 'output_tokens': 9, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pip install -U langchain langchain-openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a40c2",
   "metadata": {},
   "source": [
    "Modern way to create chat model is use `init_chat_model`. You provide two necessary information\n",
    "- model: model name\n",
    "- model_provider: 'openai', 'google_genai'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5380b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm ready to help you with tracing or any other questions or tasks you have in mind. What would you like to do?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 17, 'total_tokens': 44, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BxP8S4voThrInwCNH8PAQuLTlEu3D', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--40ae0e13-549d-47b2-91b2-bddea7871847-0', usage_metadata={'input_tokens': 17, 'output_tokens': 27, 'total_tokens': 44, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "llm.invoke(\"Hello LangSmith! Are you ready to trace?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f48ceaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-google-genai in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (2.1.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from langchain-google-genai) (0.6.18)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from langchain-google-genai) (0.3.72)\n",
      "Requirement already satisfied: pydantic<3,>=2 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from langchain-google-genai) (2.11.7)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.40.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (6.31.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2025.7.14)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\langchain\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangSmith tracing provides a powerful way to understand and debug your LangChain applications. It allows you to visualize the flow of execution, inspect intermediate values, and identify performance bottlenecks. Here\\'s a breakdown of how to understand LangSmith tracing, covering key concepts and practical steps:\\n\\n**1. Core Concepts:**\\n\\n*   **Runs:**  The fundamental unit of execution in LangSmith.  A run represents a single invocation of a LangChain component (e.g., a Chain, LLM, Tool, Agent, etc.). Each run is tracked with its inputs, outputs, start time, end time, status (success, failure, or running), and other metadata.  Think of it as a single execution of a function within your LangChain code.\\n\\n*   **Traces:** A trace is a collection of runs, forming a hierarchical tree-like structure.  It represents the complete execution flow of your application for a given input.  A trace starts at the top-level entry point (typically your main Chain or Agent) and branches out as that component calls other components.  A trace represents the entire end-to-end process for a specific request.\\n\\n*   **Spans:**  Spans are the individual nodes within a trace, representing a single run.  They contain detailed information about the run, including inputs, outputs, latency, metadata, and any errors that occurred.\\n\\n*   **Inputs:** The data that is passed into a component (e.g., the prompt to an LLM, the query to a retriever).\\n\\n*   **Outputs:** The result returned by a component (e.g., the LLM\\'s response, the retrieved documents).\\n\\n*   **Metadata:**  Additional information associated with a run or trace, such as timestamps, model names, API keys (redacted), and custom tags.  You can use metadata to filter and group traces.\\n\\n*   **Feedback:**  Ability to provide human feedback on the quality of the results produced by your application. This is crucial for evaluating and improving your system over time.  Feedback can be binary (e.g., \"Good\" or \"Bad\") or more granular (e.g., a rating on a scale).\\n\\n**2. Setting Up LangSmith:**\\n\\n*   **Account Creation:** You need a LangSmith account. Go to [https://smith.langchain.com/](https://smith.langchain.com/) and sign up.\\n\\n*   **Environment Variables:**  Configure the following environment variables:\\n\\n    *   `LANGCHAIN_TRACING_V2=\"true\"`: Enables tracing.\\n    *   `LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"`:  Specifies the LangSmith API endpoint.\\n    *   `LANGCHAIN_API_KEY=\"YOUR_API_KEY\"`:  Your LangSmith API key (found in your LangSmith settings).\\n    *   `LANGCHAIN_PROJECT=\"YOUR_PROJECT_NAME\"`: (Optional but recommended)  The name of your LangSmith project.  This helps organize your traces.\\n\\n    You can set these environment variables in your shell or directly in your Python code using `os.environ`:\\n\\n    ```python\\n    import os\\n\\n    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\\n    os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\\n    os.environ[\"LANGCHAIN_API_KEY\"] = \"YOUR_API_KEY\"\\n    os.environ[\"LANGCHAIN_PROJECT\"] = \"YOUR_PROJECT_NAME\"\\n    ```\\n\\n*   **Install LangChain and LangSmith:**\\n\\n    ```bash\\n    pip install langchain langchain-core langsmith\\n    ```\\n\\n**3. Instrumenting Your Code:**\\n\\n*   **Automatic Instrumentation:**  When `LANGCHAIN_TRACING_V2` is set to `true`, LangSmith automatically instruments LangChain components.  You don\\'t need to add explicit tracing code in most cases.\\n\\n*   **Manual Instrumentation (Less Common but Useful):**  You can use the `langchain.callbacks.tracers.langchain` module for more fine-grained control.\\n\\n**4. Running Your Application:**\\n\\n*   Execute your LangChain code.  As your application runs, LangSmith will capture the traces and runs.\\n\\n**5. Analyzing Traces in the LangSmith UI:**\\n\\n*   **Access the LangSmith UI:** Go to [https://smith.langchain.com/](https://smith.langchain.com/) and log in.\\n\\n*   **Navigate to your Project:**  Select the project you specified in the `LANGCHAIN_PROJECT` environment variable.\\n\\n*   **View Traces:**  You\\'ll see a list of traces.  Each trace represents a single execution of your application.\\n\\n*   **Drill Down into a Trace:**  Click on a trace to view its details.\\n\\n**6. Understanding the Trace View:**\\n\\n*   **Tree View:**  The primary view is a hierarchical tree representing the execution flow.  Each node in the tree is a run (span).\\n\\n*   **Run Details:**  Click on a run to see its details, including:\\n    *   **Name:** The name of the component that was executed (e.g., \"LLMChain\", \"OpenAI\").\\n    *   **Inputs:** The data that was passed into the component.\\n    *   **Outputs:** The result returned by the component.\\n    *   **Latency:** The time it took for the component to execute.\\n    *   **Status:**  \"Success\", \"Failure\", or \"Running\".\\n    *   **Metadata:**  Any additional metadata associated with the run.\\n    *   **Error:**  If the run failed, the error message will be displayed.\\n\\n*   **Filtering and Searching:**  Use the filtering and search features to find specific runs or traces based on name, status, metadata, or other criteria.\\n\\n*   **Timeline View:**  Switch to the timeline view to visualize the execution flow chronologically. This can be helpful for identifying performance bottlenecks.\\n\\n*   **Feedback:** You can add feedback to individual traces to rate their quality.\\n\\n**7. Common Use Cases for LangSmith Tracing:**\\n\\n*   **Debugging:** Identify errors and understand why your application is not behaving as expected.  Examine the inputs and outputs of each component to pinpoint the source of the problem.  The stack traces and error messages are invaluable.\\n\\n*   **Performance Optimization:**  Identify bottlenecks in your application.  Look for runs with high latency and optimize those components. The timeline view is especially useful here.\\n\\n*   **Prompt Engineering:**  Experiment with different prompts and evaluate their impact on the quality of the results. Compare traces for different prompts to see which ones perform best.\\n\\n*   **Evaluating and Improving Your Application:**  Use feedback to track the quality of your application over time.  Identify areas where your application is consistently performing poorly and focus on improving those areas.\\n\\n*   **Understanding Agent Behavior:**  Trace the steps taken by your agent to understand how it is making decisions.  This is crucial for debugging and improving agent performance.\\n\\n**8. Tips for Effective Tracing:**\\n\\n*   **Use Descriptive Names:**  Give your LangChain components descriptive names to make it easier to identify them in the trace view.\\n\\n*   **Add Metadata:**  Add custom metadata to your runs and traces to provide additional context.  This can be helpful for filtering and grouping traces.  For example, you might add the user ID, the query, or the version of your application.\\n\\n*   **Redact Sensitive Information:**  Be careful not to log sensitive information, such as API keys or personally identifiable information (PII).  LangSmith automatically redacts some common sensitive information, but you should double-check.\\n\\n*   **Use Projects:**  Organize your traces into projects to keep them separate and manageable.\\n\\n*   **Leverage Feedback:**  Collect feedback on your traces to evaluate and improve your application.\\n\\n**Example:**\\n\\n```python\\nimport os\\nfrom langchain.llms import OpenAI\\nfrom langchain.chains import LLMChain\\nfrom langchain.prompts import PromptTemplate\\n\\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\\nos.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\\nos.environ[\"LANGCHAIN_API_KEY\"] = \"YOUR_API_KEY\"  # Replace with your actual API key\\nos.environ[\"LANGCHAIN_PROJECT\"] = \"MyLangChainProject\"\\n\\n# Define a prompt template\\nprompt = PromptTemplate(\\n    input_variables=[\"topic\"],\\n    template=\"Tell me a short story about {topic}.\",\\n)\\n\\n# Create an LLM\\nllm = OpenAI(temperature=0.7)\\n\\n# Create an LLMChain\\nchain = LLMChain(llm=llm, prompt=prompt)\\n\\n# Run the chain\\nstory = chain.run(\"a magical cat\")\\n\\nprint(story)\\n```\\n\\nAfter running this code, go to the LangSmith UI, select your \"MyLangChainProject\" project, and you\\'ll see a trace for this execution. You can then drill down to inspect the prompt, the LLM\\'s response, and the overall execution time.\\n\\nBy understanding these concepts and following these steps, you can effectively use LangSmith tracing to debug, optimize, and evaluate your LangChain applications.  It\\'s a powerful tool for building robust and reliable AI systems. Remember to replace `\"YOUR_API_KEY\"` with your actual LangSmith API key.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--562da16e-2966-4bd1-867f-119957d7d0f5-0', usage_metadata={'input_tokens': 8, 'output_tokens': 2030, 'total_tokens': 2038, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install -U langchain-google-genai\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
    "\n",
    "llm.invoke(\"How to understand the LangSmith tracing?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
