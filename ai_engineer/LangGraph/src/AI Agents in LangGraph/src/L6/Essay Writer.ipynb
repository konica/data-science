{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911b3b37-3b29-4833-94f2-bfe47af00c83",
   "metadata": {},
   "source": [
    "# Lesson 6: Essay Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "import sqlite3\n",
    "conn = sqlite3.connect(\"checkpoints_essay.sqlite\", check_same_thread=False)\n",
    "memory = SqliteSaver(conn=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an essay. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the essay along with any relevant notes \\\n",
    "or instructions for the sections.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 5-paragraph essays.\\\n",
    "Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed: \n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.pydantic_v1 import BaseModel\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT), \n",
    "        HumanMessage(content=state['task'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"plan\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use tavily to search for content based on the queries generated by the research plan node\n",
    "def research_plan_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        print(f\"Search results for query '{q}': {response['results']}\")\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "98f303b1-a4d0-408c-8cc0-515ff980717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essay writer node that generates a draft based on the plan and content\n",
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=WRITER_PROMPT.format(content=content)\n",
    "        ),\n",
    "        user_message\n",
    "        ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content, \n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bf4dcb93-6298-4cfd-b3ce-61dfac7fb35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teacher assistant that critiques the draft and provides feedback\n",
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT), \n",
    "        HumanMessage(content=state['draft'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "932883a4-c722-42bb-aec0-b4f41c5c81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research critique node that searches for additional information based on the critique\n",
    "# and updates the content with relevant findings\n",
    "def research_critique_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "        HumanMessage(content=state['critique'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ff362f49-dcf1-4ea1-a86c-e516e9ab897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a7e15a20-83d7-434c-8551-bce8dcc32be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "54ab2c74-f32e-490c-a85d-932d11444210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1a46bb3f710>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a833d3ce-bd31-4319-811d-decff226b970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1a46bb3f710>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.set_entry_point(\"planner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "76e93cce-6eab-4c7c-ac64-e9993fdb30d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1a46bb3f710>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_conditional_edges(\n",
    "    \"generate\", \n",
    "    should_continue, \n",
    "    {END: END, \"reflect\": \"reflect\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fd2d0990-a932-423f-9ff3-5cada58c5f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1a46bb3f710>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "27cde654-64e2-48bc-80a9-0ed668ccb7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4871f644-b131-4065-b7ce-b82c20a41f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAIiCAIAAAChdyHrAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdcE/f/B/BP9iIJIywDqAiCCggy3Huvojiq1hVsFRVHldbVqnXW4uy31doqqXuitY66rXuhTBEnsjcyssj8/ZH7UYpoUZN8Eng///AR7i5378S8cvf55O5zJJ1OhwAACJFxFwCAuYAwAECAMABAgDAAQIAwAECAMABAoOIuANSXTKItzauSVaplFRq1RqdRWkCfOINFpjHJHC7Fik8VuDBwl/MfSPA7g5mrfK1++rAyPUWqrNKyrShsHpXNpVhZU1VVWtyl/TcylVxepJRVqpksSuZTWfM2HHc/blNvFu666gZhMF+qKt2tU8WVpSpbZ4a7D8epGRN3RR9FVqlJT5EWZikKMhWdhgrcvNi4K6oNwmCmkm+W3zpZ3GmowLczH3ctBlacU3XzVAmHS+0zzgF3Lf8CYTBHF/cXWNvTg/ra4C7EiPJeKY7/nDPuazdrexruWggQBrNzakeeR1sr72Au7kKMTqPW7f8hc+QsFxaXgrsWBGEwO0c2Z/l3t/EMsMJdiOns/T5jwAQngRB/XxP8zmBGLh8qbN2B36iSgBAav7DpoY1ZOjPoG4M9g7lIvVshq9A07HbC25QVqe6cKRkwyQlvGbBnMBd/Hyls16sxJgEhZG1PozPJj+5U4C0DwmAW7v5VGtzPlmwWzUg8Og0V3DpVjLcGCAN+ajXKz1AE97PFXQhOTDY5sKdNyi2cOwcIA34vkyqZHFP/RyxYsODEiRPv+6znz58PGTLEOBUhZ3fWkzgIQ+OWniJ19zF1D9KjR48+4FkpKSlGqIXg3JxZWqCskmHrV4LeJPyObskOixSSKSRjrPzGjRu7d+9OTU11dHT09fWNjIy0trbu0KGDfi6fz7906dKLFy+OHj167969/Pz85s2bjxgxYvjw4foFevToERERcfHixYSEhPHjx+/du1c/PSoqasyYMQav9ubJEnsho2U7TJ3LOoCVpEwds+ylkVb++PHj4ODgnTt35ufnX79+/dNPP50zZ45Op1MoFIGBgX/88Yd+sWnTpg0fPvzevXv3798/fPhwYGDg7du39bP69u0bGhoaHR199+5dtVq9ZcuWwYMHG6lanU5373zJ7TPFxlv/u8H1DJjJKtVsrrH+FxISEhgMhkgkIpFIjo6OPj4+z58/f3OxdevWyWQyZ2dnhFBQUNAff/xx69Yt/d6DQqE4ODhERUUZqcJaODxq/iuFabb1JggDZrJKDZtnrC5Vf39/uVw+Z86cjh07du3a1cXFJSgo6M3FtFrtvn37bt26lZmZqZ/SvHnz6rmtWrUyUnlv4vCo0nK1yTZXCzSgMdNpEZVurP8Fb2/vLVu2CASCLVu2DBs2LDIyMjk5udYyGo1m1qxZ8fHxs2fPvnr1alxcnI+PT80F6HS6kcp7E5lCIhmn7VQfsGfAjM2lVJaqjLf+zp07d+7cOSIi4t69e/v27Zs7d+758+drLpCampqWlrZt27bg4GD9lMrKSuPV826SMhWTje0LGvYMmLF5FFmlxkgrj4uLu3PnDkLIwcFhyJAh8+bNKy8vLygoqLlMWVkZQsje3l7/5/PnzzMyMoxUz3+SVWg4PGxf0BAGzKz4VJ6tsa5uiY+Pj4qKOn78eFlZWUpKyqFDhxwdHR0dHRkMhoODw7179+Li4po2bUoikfbt2yeRSNLT09evXx8SEpKXl1fnCt3c3IqLi69evVrdujAstUpn42i6o7JaIAy4kRCTTX6ZLDXGuidNmjR8+PDo6Og+ffpERETweLzt27dTKBSEUHh4+N27d+fPny8QCFatWpWQkNCjR4/58+fPmjUrLCwsMTFx3Lhxb66wS5cu/v7+8+fPr3WsZSiP7pRjvDYafnTD7/G9ipwX8j5jHXEXgllhVtXfRwtHf+mKqwDYM+DX3MfKeM0GC5KXrvAK5GEsAHqT8GOyyTYO9ISrZf7dretcQK1W9+nTp85ZSqXybV2fHh4eO3bsMGil/9izZ8/OnTvrnMXj8Soq6j7frk+fPt98802ds7Qa3c2TRTOiPQxa5vuBwySzoFHrti96OSO6xdsWyM3NrXO6RCKxsqr7TB4ajVbdR2RwlZWVb+uBraqqYjDqvqCZxWLZ2NR9AdONE8VW1tS3fR2YBoTBXCReLUdk1LZrQxslqT7kEu2lAwVDvnDGWwa0GcxF2+78nGcyI3Urmbn9P2T0GoN/QDEIgxkZFO5848/iwqwq3IWY1NEt2f3GO7HNYOgkOEwyO4c3ZnUYbGeGQ5Eaw9Efs/uMcbR2MItB9SAM5ujE9lwPX6s2nXD2MxpbebHq0MasIZ83aeJuLgMqQxjM1P3zpWlxlZ2GCFr4cXDXYmCySs2tk8VVCm2fsY4MlhkdqEMYzFd5sermyWIqjezgymjehsMXmMWxxAfTaVH6I2l+hiLtfkWnIQIzHEwWwmDuCjIVz+IlL1OkHB7Fik9l86gcHoXDp2pUFvAfp0OoslQlrdBQaKRHt8qbt+G0aGvlFWh2MdCDMFiM1wXK4lyltEItq9BodTql3JCjSBQVFWVlZbVr186A60QIsawoNDqZzaPwbGkunmZ6w55qcDqGxbBxpBvv9OYbN57eeXEu6tMBRlq/RTCj5gsAeEEYACBAGAAgQBgAIEAYACBAGAAgQBgAIEAYACBAGAAgQBgAIEAYACBAGAAgQBgAIEAYACBAGAAgQBgAIEAYACBAGAAgQBgAIEAYACBAGAAgQBgAIEAYACBAGABCCJFIpLfdDqvxgDAAhBDS6XRKpRJ3FZhBGAAgQBgAIEAYACBAGAAgQBgAIEAYACBAGAAgQBgAIEAYACBAGAAgQBgAIEAYACBAGAAgQBgAIEAYACCQdDod7hoANoMHD87Pz0cIabVaMpms0+lIJJJWq42Pj8ddGgawZ2jURo8eTaVSSSQShUIhkUj6PLRq1Qp3XXhAGBq1MWPGuLm51ZzCZDJHjx6NryKcIAyNGoPBGDJkCIVCqZ7StGnTYcOGYS0KGwhDYzdq1KimTZvqHzMYjDFjxuCuCBsIQ2PHZrOHDBlCpVIRQi4uLqGhobgrwgbCANCoUaOEQiGdTh8/fjzuWnCCrlVzpNXocl8qyopUVXKNabb44MGD5OTkyZMnm2ZzFCqJw6PaOdNtncxosCYIg9lJT5HGXXxNppCauLOVCi3ucoyCSie/LqzSqHRcG0qvTx1wl0OAMJiXnOeKO3+V9JsoxF2IiaTeKS8vUvQb74i7EARtBvNSUaK6eCC/8SQBIdS6A59rS7/+RzHuQhCEwbw8vFwW0FOAuwpT8+ls8zJZoqrCf0AIYTAjea/kfHsa7iowYHGpxbn4R3qFMJiRKpmWZUXFXQUGHC5VVqHGXQWEwZxotTrUKLszdMgsXjeEAQAChAEAAoQBAAKEAQAChAEAAoQBAAKEAQAChAEAAoQBAAKEAQAChAEAAoShYYo9drBPv/a4q7AwEAYACBAGAAgQBgt24OCuYWF9rt+4MnxE3159gsdPHH7x0tk3F0tPf7Hlx3UTJ48YMKjztIjxp04fr571SWjPE38eFf/+S8/eQUM+6b5i5aLS0hKE0PPnT3v2Dnqc9uibpfN79g76dOzgX7Zvqb5cvri4aMXKRZ+OHTwsrM+a75fm5Gbrpx+N3T9y9IAbN//u06/9/bg7pnobDAbCYMEYdIZUKvn77wsH9p08HnuhR/c+a9Z+W/3RrPa/n6LjHtydO2fh2jVbBg4M3bBxdfUnlc5gHDj4O4PB/PPEld9jjiYmPdy95zeEEJ1ORwit37Cyb59B58/eXrjgu0OH9/x99SJCSK1Wz4uKSE5JiJr/rXjnYS6XN336hLz8XIQQjUaXy2UHD+1evGhly5aWN3oxhMGC6RBSq9Vhw8cwmUw+31o0OYLFYv3994Vaiy1bti563c/tAoID/IOGhY7y9PC6d++WfhaJRHJ1aTpu7GSuFVcgsA8MbP/0WRpCiEwmI4R6dO/bvVtvGo0W4B/k6Oj09OljhFBi0sOsrIxFC1cEB3WwsbGdOX2elRU3NvYAQohCochksinhM3r17Mfn8XG8JR+lMV5k2MB4eHjpH1AoFGdnYWbWq1oL6LTaI7H77t27lZ2dqZ/StGnz6rk1v8K5XJ5EUlnnLCsrrn5WcnICjUZrFxCsn04mk/3atktO/ud+Dl4tWxv6JZoIhMHiMRiMGo+ZMqm05lyNRrNg4SydTjdt6uwA/2AOhzMj8l/D5pFIpLetWb9/qEUiqVSpVD17B9WcaGf3z6Ae+kMsSwRhsHhSqZTD4egfV1UpmExmzblPnqQ+fZa2Yf226u/ymt/9H8DOTsBisVav2lRzIpXSED5IDeE1NHLxCfe7dO6BEJLJZNnZmT179Ks5t7y8DCEksLPX//ny5fOsrAyvj2jdurt7yuVyJ6cmzk5N9FNycrNtbew+7kWYBWhAWzYqlXrs2MHs7EyNRhMj3qZUKnv06FtzgWbNW5BIpCNH90kkkoyM9J9+Xh/YLiS/IO+Dt9g+pFNISKfo6BUFBfllZa+PHT8UETH+3PlThng1mMGeweKNCBs758svSktLOBzO4kUrhU1cas51dmqyZPGqPXt3DA3t4eLitnjRyoKCvO9WLPxi6rjfft3/YVtcu3rznydjV6xalJqa7ObWbODA0GGhowz0anCCgYfNSMyy9CFfuLG4lHosi/QnIG3dtvHShXtGrsvorh7N9w6y8mhrhbcMOEwCgABhAIAAYbBgI8LGNIBjJPMBYQCAAGEAgABhAIAAYQCAAGEAgABhAIAAYQCAAGEAgABhAIAAYQCAAGEwI3wB3RzuDY6BDjE59T1X13ggDGbEyppSkqfAXQUGeekyQRNGPRY0LgiDGfHpaP0i+aMuULZEmWlSN28Ok43/o4i/AlBN6MFsGWB1/VgB7kJMJz9dnnrndf8JjrgLQXClmzl6eKUs94WcaUV1aspWqxtmE4JKJZUVKRUyTXlR1fAZQjLlrcPVmBKEwRyV5quyn8kqXqtlFWrTbLGioqKkuKS5e/N6LGsAdCaZyaE4uDDcfTmm2WJ9QBgAQgjduHEjNjZ206ZN9Vi2wYI2AwAECAMABAgDAAQIAwAECAMABAgDAAQIAwAECAMABAgDAAQIAwAECAMABAgDAAQIAwAECAMABAgDAAQIAwAECAMABAgDAAQIAwAECAMABAgDAAQIAwAECAMABAgDQAghEonEZDJxV4EZhAEghJBOp1MoGuMA4DVBGAAgQBgAIEAYACBAGAAgQBgAIEAYACBAGAAgQBgAIEAYACBAGAAgQBgAIEAYACBAGAAgQBgAIEAYACDATdEbtaFDh+bk5JBIxMeATCbrdDqtVhsfH4+7NAxgz9CojRw5kkqlkkgkMplMJpP1V/l4e3vjrgsPCEOjNnLkyGbNmtWcwmAwxowZg68inCAMjRqHwxk0aBCFQqme4ubmFhoairUobCAMjd2oUaOaNm2qf8xgMMaOHYu7ImwgDI0dh8MZPHgwlUpFCAmFwmHDhuGuCBsIA0CjRo0SCoV0On3cuHG4a8EJulYNSadF+a8UrwuVVXIN7lrez/3795OSkqZMmYK7kPdDoZKtrKl2znS+gPbxa4MwGEzOC/nt0yVaLWrSgq1SwLtqCjQGqTS/SqtBds60rsMEH7k2CINhFGRWXTtW1HeCkEIl4a6lMUq6+lqpUPccbf8xK4E2gwHIKjUnf8sdIHKBJODi192GSqfcPlPyMSuBMBjAg4uvA/t87D4afCT/nrZp9yu1mg8/0oEwGEDeK7lBGnDgIzHYlJJ85Qc/HcJgAFUyLYdHxV0FQFwbmqTsw/vxIAwGoFFDN4RZ0Gp0CMFhEgAfDcIAAAHCAAABwgAAAcIAAAHCAAABwgAAAcIAAAHCAAABwgAAAcIAAAHCAGrLzs7s2TvoftwdQ60w9tjBPv3aG2ptxgNhAIAAYQCAAGfhY3A0dv/BQ7vnzlm4/LsFYcPHzJj+pVqt/m3HT3fu3iguLvTzazcsdHT7kE76he/cuXHw8O4nT1Lt7R1bt/b9YkqknZ0AIVRcXLR128ZHqUlVVVUhIZ0mTZwqbOKif8rt29cvXzmXmPRQIqls5e0zYfzn/v6BdW63vKJ827ZN586f4vOtg4M7Tv18lr29g34lGo3mh+gVf539085O0L17n1kzo979olIfp8yMnPzd8h9+37U9Pf2FnZ2gd68B0yPm1losPf3FnyePPnh4r7Awv6lb86FDRwwZPFw/65PQnlOmzCwtLd69ZweHwwkJ7hQ5M8rW1s7Qb/9bwZ4BAxqNLpfLDh7avXjRyk8+GYkQ2rR57bHjB0eEjT2w/1SXzj2+XTr/xs2/EUJPn6Ut+XZeUGCHXeLYGRFfPnuWtn7jKoSQWq2eFxWRnJIQNf9b8c7DXC5v+vQJefm5CCGZTLZqzRK1Wr1o4YrVqzYJha5Lvv2yrOz1m9tVqVSLFs8pryjbuOGXyJlReXk5CxfPVqvV+iJ37f61XbuQjRt+GTli3LFjB69eu/TuF8WgMxBC+/bFrFm1+eyZm9Mjvjx2/OC5c6dqLfa/n6LjHtydO2fh2jVbBg4M3bBxdXXjhM5gHDj4O4PB/PPEld9jjiYmPdy95zfj/A/UDfYMGFAoFJlMNiV8RoB/EEJIoVCcv3B63NjJnwwdgRAaPGhYUnL87t2/dencIyU5gcFgfDZORCKRHBwcW7XyeZn+HCGUmPQwKytjw/pt7QKCEUIzp8+7fetabOyByJnz2Wz2jt8OsllsPt8aIeTp4X3y1LGUlMQuXXrU2u7fVy8+fpyyS3zUza0ZQkgodI09dkAfG4RQu4DgPr0HIIQC/IOOxu5PSo7v3q33O14UiURCCHXr1tvJyRkh1LtX/wsXz1y6fLZ//yE1F1u2bJ1cJtMvE+AfdObMH/fu3QoO6qBfg6tL03FjJyOEuFbcwMD2T5+lGfm/4l8gDNh4tWytf5CW9kitVgcHdaye5d828Pz501Kp1MfXXy6XL1w8JySoY4eOXYVNXPSf4+TkBBqNpk+C/r4Kfm3bJScTN1WQSaU7dvyUmPSwpKRYP6Ws/PWb201Pf25lZaVPAkKolXebbxav0vcmIYR8ffyrn8LnWyurqurzolq4e1Y/Fgpdb978u9YCOq32SOy+e/du6beCEGratHn13JYtW1U/5nJ5EkllfTZqKBAGbOh0uv6BRFqJEJo1p/ZodqWlxS09vdeu2XLt2qVfft3y09YNwUEdJk+a1rq1r0RSqVKpevYOqrm8vi2Rn58358vPg4M6Lv1mbevWvhqNZsCgzm/ZroTJZL2tPAr1n8+G/lu/PmqukMlgSiWSmnM1Gs2ChbN0Ot20qbMD/IM5HM6MyMk1F6j/howBwoCfra0AITR/3hKh0LXmdIHAASHUoX3nDu07iyZHPHx470jsvkVL5h47et7OTsBisVav2lRzeSqFihC6fOWcSqVa8PVyJpOJECovL3vbdjlsjkwm1Wq1+tuUGETN73JFlYLJ+lfYnjxJffosrfrortby2EEY8HN1bUqn0ykUiv4QCCFUWlpCIpFYLFZ8QpxarQ4O6mBv79C//xB7B8f5UdMLiwrc3T3lcrmTUxNnpyb6p+TkZtva2Ok//VwuT58EfcPgbdv1atlaJpM9efq4lXcbhNCrVy83//j9nFkLaLQPH/YmIfFBly499I+fPUtr3qxFzbn6ZArsiHHvXr58npWV4VXj0Agv6E3Cj2vFnTxp2u+7ticnJygUir+vXpwXFfHj/35ACCUlxS9dFnXq9PHy8rLUxynHjx9ycHB0sHdsH9IpJKRTdPSKgoL8srLXx44fiogYf+78KYSQR4uWJSXFp8/8oVar79y9mZKSYMWxKizMf3O77dt3Fgpdf/31x+s3rtyPu7P5x+9LSopdXZt+zGu5H3db3zt09dql5OSE3r0G1JzbrHkLEol05Og+iUSSkZH+08/rA9uF5BfkfcwWDQj2DGZh7JhJHh5e+w/+Hhd3h8fjt2ntFzX/W/30ysqK//0UvWHjaiaT2bNHv40btutvtLN29eY/T8auWLUoNTXZza3ZwIGhw0JHIYT69BmYkZku/v2X9RtWhYR0WvDVsr37Y/bs3SmVSWt9T1Op1PU/bF27bunSZV8hhDp37j5v7mIq9aM+EuPGTP5l++avFzynUCgjR4yr1ZXk7NRkyeJVe/buGBraw8XFbfGilQUFed+tWPjF1HG//br/Y7ZrEDDwsAH8/t2rASIXDr9Rf7O8fPl8yhdjtmz6zc8vAFcNlw/m+XXhNW/D+bCnw2ESAIRG/WUG3suhw3v27t1Z56zm7h5zZy80eUUGBmEA9TVo0LBub/kRmkalCQT2Vy7FmbwoQ4IwgPriWnG5VlzcVRgRtBkAIEAYACBAGAAgQBgAIEAYACBAGAAgQBgAIEAYACBAGAAgQBgMgGdPU6vg5F/8yBQSg0358KcbtJhGisunFucocFcBUM4zqb2Q8cFPhzAYQJuO/PQUM7qWt3HKeCxt0daKRv/wIQUgDAbQxJ3pGWB143gB7kIar8IsxaNbr/uOc/yYlcCVbgYTf6UsN13BsqI6uDG1GnhXTYFCJZUXq6rkmuJsRdhMIYX2USPNQBgMqSRXmfVUJinXSMpUuGt5P5WVlaUlpU2bfdRoAKbHYFEYbLK9C8PT3+rj1wZhAAghdOPGjdjY2E2bNtVj2QYL2gwAECAMABAgDAAQIAwAECAMABAgDAAQIAwAECAMABAgDAAQIAwAECAMABAgDAAQIAwAECAMABAgDAAQIAwAECAMABAgDAAQIAwAECAMABAgDAAQIAwAECAMABAgDAAhhMhkMofDwV0FZhAGgBBCWq1WKpXirgIzCAMABAgDAAQIAwAECAMABAgDAAQIAwAECAMABAgDAAQIAwAECAMABAgDAAQIAwAECAMABAgDAAQIAwAEuCl6ozZkyJDc3FwS6V8fA51OFx8fj7UuPGDP0KiFhYXRaDQSiUSuoWXLlrjrwgPC0KiNHj26WbNmNafQ6fRPP/0UX0U4QRgaNSsrqwEDBlAolOoprq6uYWFhWIvCBsLQ2I0YMaJ658BgMEaPHo27ImwgDI0dj8cbOHAglUpFCAmFwhEjRuCuCBsIA0AjRoxwcXFhMBhjx47FXQtOVNwFAEJRdlVpvrJKocGy9f4dv3j48GEL+55JN8pMv3UKlcy1odo60a34OD+Q8DsDfqX5yitHipQKrbM7W63S4i4HAwaTUpSjIJNJQg9mcF8bXGVAGDArLVBd2FfQc7Qzi0upx+IN3J3TRdYCanA/PHmANgNm+9dlDAp3gSTodRhs/7pQlXSjHMvWIQw4xV14HdRXgEi46zAngX0Fj26X63AcLUIYcMrPVHBtabirMC90Jlkh1Uor1KbfNIQBpyqZlmMNHXq18QR0STmGXjUIA05qlRbL8YCZ06i0CEe/DoQBAAKEAQAChAEAAoQBAAKEAQAChAEAAoQBAAKEAQAChAEAAoQBAAKEAQAChAEAAoQBGMCwsD65eTm4q/hYEAbwsXJys8vLMQwjYHBwMr2FefQoacuP67JzMv382k2a8MX/fl7v7dV69qyvEULJyQm7dv/65EmqrZ2gQ/sukydNY7FYCKHY2AP7D/6+cf0vS5d/lZn5yt3dY/TI8f37D9Gv8MxfJ06eOvbq1Qt3d89ePfuPCBujn/7t0ig6nW5v73jo8J5VKzZ07tz92PFDd+5cf/w4hc5gBPgHTZky09mpyf24O18viEQIfTY+tFvXXt8t/6G4uGjrto2PUpOqqqpCQjpNmjhV2MQF63tWX7BnsCRyuXzxN1/aCezFO4+Ei6b/7+f1JSVFJDIZIZSZ+errhZEqtWrrz7uWffv9s2dp86IitFotQohGp1dWVmz5cd3Cr5dfvni/S+ce0RtWFhcXIYQuXDgTvX6lt1frA/tOiiZHHD6yZ+u2Tfpt0Wi0J09S01+9WLNqk49P24SEB//7KdrXN2DFivULF3xXWFSwZu23CKHgoA5rV29GCO3be+K75T+o1ep5URHJKQlR878V7zzM5fKmT5+Ql5+L+52rFwiDJbl562pFRfn0aXMdHZ1aenqHi6YXFhboZ1289BeNSluxPNrVtam7u8f8+d+kpT26dfsaQohMJqtUKtHkiFatfEgkUr9+QzQazfPnTxBCJ08f8/MLmDN7gbW1TVBg+0kTpx47flB/zEOhUIpLilYsj+7YsSufb+3r6x+z49C4sZMD/IOCgzqMHjU+JSVRIpHUqjAx6WFWVsaihSuCgzrY2NjOnD7PyoobG3sAx7v13uAwyZJkZLzk8fhubsTQqEGB7a2srPSPU1ISvb3b8PnW+j+FTVycHJ0TEx926dxDP8Xbu43+AZfLQwhJpBK1Wp2amjx50rTq9QcEBGs0muTkhC5deiCEmro1ZzAY+lkUCiUnJ+unn9c/eZoqlUr1E8vKSqsL0EtOTqDRaO0CgvV/kslkv7btkpMt424PEAZLIpVJ9c2Aanwe8emXSCqfPX/Ss3dQzbmvX5dUPyaRag/CoVAoNBrNzpitO2O2/utZZaX6B/T/TwJC6Nr1y8uWfz1xwuczZ8x3d/e4c+fGoiVz36xQIqlUqVS1yrCzE7z/a8UAwmBJGHSGWv2vYSNKSov1D2ztBL4slmhyRM251VGpk5WVFZPJHNB/aLduvWtOFzZxfXPh06eP+/kFVK9fIq19gKRnZydgsVirV22qOZFKsYyPmWVUCfScnYWlpSXl5WX6w6H7cXcUCoV+Vgt3zytXzvu3DazeA7x69dLFxe3dK3R395Qr5AH+xBe5UqksKMhzcHB8c8mKivImNTqFrl+//NYVyuVOTk2cnZrop+TkZtva2H3QyzU1aEBbko4dupJIpC0/rpPL5VlZGQcO/C4Q2OtnjR49Qa1R/7R1g0KhyMx89cv2LeGff5qRkf7uFU77YvZnAYJkAAAgAElEQVS1a5fO/HVCo9EkJcV/t3Lh/K+mK5XKN5ds0aLlg4f3EhMfqtXqw0f26u9vUlCYjxBydWuGELp69eLjtEftQzqFhHSKjl5RUJBfVvb62PFDERHjz50/ZZz3w8AgDJbE3t7hy7mL4hPiho/oE71h5fjxUxgMpv4ghM/j79xxiMlgfj517CTRyMSkhwu+Wtaihee7V+jnF7B9296kpPjhYX2+Xhgpl8lWrdxIp9PfXPKLzyMD24Us/mZuvwEdS0qKF3y93NPDK+qrGdeuXxY2cRnQf2iMeNvOnT8jhNau3tytW+8VqxYNH9H3xJ9HBg4MHRY6ymhviSHBwMM4HdqYFTLQQdCEUY9lCTm52Vwuj8flIYQ0Gs2gIV0jps0dPqxB3W7nr5jsbsMFTs2YJt4utBksyevXpdNnTGzp6T1lykw+33rHjp8YdEb3fzd/wQeDwyRLYmNju3b1Zo1G88238yIixktl0p/+J7a1tYzmqfmDPYOFadPGb9PG7biraJhgzwAAAcIAAAHCAAABwgAAAcIAAAHCAAABwgAAAcIAAAHCgIdCoVi2bJn+QmRgJiAMJlVaWrp7926EUElJSUhISPUJ2MAcQBhMpKysDCE0Z84c/eU4QqFw8ODBPDuaRgVnDddGpZMZTIrptwthMLqzZ89269atvLwcIbRnz56pU6dWz+JaU4tzFVirMztajS7/lczGCcO94iEMRqHRaA4fPnzkyBGEkI2NzdmzZ5s2bfrmYl5BvOxnUhwFmq+XyRKfju+6dNt4IAwGlpycjBC6dOlSRkZGz549EULt27dns9l1LmwvpPt05F09mm/yMs1U5mPpq0eV3cLwjKYBV7oZhk6nk8vlYWFh/fv3//LLL9/ruY/vVTy+V2njxHBwZdVj8QaIQiGVFlQpFdqyQkXoNCEJ01c0hOFjXb9+fe/evVu2bNHpdFKpVCD4kG+1siJVeoq0olRVWaaux+KGJ5VKy16XCV2EJt5uSkoKmUxW62TyqnIlKtJx8gQCgaur69ixY01cCYThw6WkpNBoNC8vr19++SU4ODgwMBB3RR/lxo0bsbGxmzZtqseyhjR27NinT5+SSCStVqsf5Ean02m12oSEBBNXAmF4bwqFgslk7t279+LFi2vXrnV2dsZdkWHIZLKKigonJycTb/f27dvLly8vKSmpOVGj0cTHYxiREsJQX69fv161apWrq+vcuXNLSkrs7ODKY8P45ptvzpw5QyYTDQWdTvfgwQMslUBv0n949eqV/jfjwsLCTz75ZO7cuQihhpeEhw8frlu3Dsum58yZ4+r6rwEtY2NjsVQCYaibRqORyWQIoaioKC6XixDy8vLq3r077rqMRSaT5efj6eG1t7cfPnw4k8lECNna2j548ODp06dTpkzJzs42dSk68IZdu3aFhISUlZXhLsR0pFJpXl4exgImTpwYGBhY/WdCQkJoaOj27dtNWQPsGQhyuTwmJubChQsIIW9v77t37/L5fNxFmQ6bzTZ967mmXbt2CYX/dOy2bdv2jz/+QAgNGzYsMTHRNDVAAxolJia2bdv28OHDJSUlkyZNetuvxQ3bw4cPL1y4sGDBAtyF1JaTk7N06VIPD49FixYZe1uNes9QUFDQtWvXR48eIYRGjx49ffr0xpkEvG2GdxMKhTt37mzZsmXXrl0vX657HHxDaYx7hhMnTpw5c2b79u2lpaUsFqvWvXAaJ1y/M9SfXC5ftmyZVqtdsWKFkb6zKMuXLzfGes3QnTt3SCQSj8e7ePHixIkT7ezsWCwWjYbhVGEzRKPRat2dzdzQaLS+ffvS6fQpU6ZwudzWrVsbfBMN/zBJf0fKH374Ye/evfpO0sjISE/P/7hxQWPz4MGD77//HncV/61Hjx7Xrl17/vx5eHi44fteTdl1ZWKZmZlTp049dOiQTqdrVP2kH+D69etz587FXcV7SExMDA0N/eWXXwy4zgbYZkhOTk5ISJgwYYL+V31LP4XONORyeUVFhaNjHXdzM2e//fbbqVOnVqxY0bZt249fW8MJQ3l5OY/HKy0tjYqKmjJlSpcuXXBXBEwhJydn2bJlLVq0MEDfqwH3Mhh9//33vXr10mg0arUady0WKS4ubu3atbir+HCxsbGdO3e+dOnSx6zEghvQpaWlP/744/379xFCvXv3vnTpEplM1t+FErwvuVxeUFCAu4oPFxYWdvHixbNnz86fP18q/cDLyi3vMEmj0aSmpvr6+u7cuZNGo40bN45KhfsPfSwLbTO86erVq0uXLo2MjBw16r1vMWphe4a0tLROnTrpfyudMmXKxIkTIQkGwWKxGkASEELdu3e/evXqy5cvRSJRVlbW+z3ZcIdtRrRz587Zs2frdLr8/HzctTRMlt5meFNSUtKwYcO2bdtW/6eY9Z7hwoULFRUVSqWyqqpq8eLFCKGG8e1lhiy9zfAmX1/f48ePU6nUTz75RD9+z38yxzZDeXk5n8+fOXMmj8dbsWIFnDFhAgqFQiKRfNjQHmYuNzd3yZIlXl5eCxcu/I9Fjbmnem8pKSmfffbZ1atXdTpdVVUV7nJAw3HkyJGuXbteuXLlHcuYxZ6hvLz83Llzo0ePvnnzpkAg8PLywl1RoxMXF3fu3LklS5bgLsSIZDLZ0qVLyWTyDz/8UOcCZtFmWLRoEYfDQQh17twZkoCFUqnUDw/egLHZ7PXr13O53IMHD9a5gFn0Sy5fvtzaGs9Ys0CvXbt2LVu2xF2FKTg6OlZUVNQ5yyzC4ODggLuExo7JZOrHp2jMzOIwaeHChU+ePMFdRaMWFxe3evVq3FVgZhZhKCgoUCqVuKto1BQKRXFxMe4qMDOLw6R169ZBmwGvoKAgY1xIaVnMIgzQZsAO2gzmcpgEbQbs4uLiVq5cibsKzMwiDNBmwE6hUJSWluKuAjOzOEyKjo7m8Xi4q2jUoM1gLmFokOeHWRZoM5jLYdJXX32VlpaGu4pGDdoM5hKG4uJilUqFu4pGDdoM5nKYBG0G7KDNYC5hgDYDdtBmMJfDJGgzYHf//v3vvvsOdxWYmUUYoM2AXVVVVVlZGe4qMMN5mNSuXTuEEIlE0ul0kydP1ul0JBLJzc3t+PHjGKtqnIKDg318fHBXgRnOPYObmxuZTCaRSNX/MpnMSZMmYSyp0WIwGHCuJM4wDB48uNYUoVA4dOhQTOU0atBmwByGTz/91MXFpfpPBoMxatQoGCwVC2gzYA4Dj8cbOHAgiUTS/+nm5jZixAiM9TRmwcHBy5Ytw10FZph7k8aMGaPfOTAYjBEjRpDJZtG71QhBmwF/GPh8/oABAxBCrq6usFvACNoM9eparShVl+RWSSvURqog0HPYQ8+iTp06Pbpd9wAeH4/GoNg40BxcGUZafwMAbYb/DsPZXfnFeUq+gM5kGa9dSx45ZBpCKC/dWNf3MDjkh5df01nk9gNsXTzgrs//iIyMvHXrlv4xiUQKDAzU6XQODg5nz57FXRoGbw2DToeO/ZzjGcDvPMysbw9cTwE97dQq3bnfc3qNtndwg10EYfLkyc+ePSspKameotVqG+0tId/aZjj5W27rEOvmPg0hCXpUGmnwFy6nxXmVr411yGdxgoKCvL29a04RCoWN9nfPusOQ90qBSGQXL47J6zG64P72cRdf467CjEyYMMHe3r76T39//0YyzuSb6g5DSW4Vk90wezn5drS8l3LcVZiRoKCg6sGehULh+PHjcVeETd2feJlEw7Whm7wYU2DzqWoV/lH4zcqECRP0l5S8edTUqNQdBp0GadRakxdjEjqkkGlwF2FeAgMDvb29nZ2dG/lPPWZxpRuoJ2m55nmSJO9VVWWpSi7RsKxoZUWGuamCNyvS01tzcz/9Jko3yAopNDKLQ2FzKQ4uzGatWc7NLeAyOgiDZUi9U5F4vbyyTM0VsFl8FsuOzXWmUBkUGzfclb2FVqtTK9WqKk1ervZpQpFCovLtzPfvbs3mmu+JmBAGc/csXnLjz2KeA9vazc7Zx5J+IaGziU+XrQtXo9KWlCj2fp/p1c6qc6i9ed682yyLAv/vz9/yZRKd0NeZzrLs/ykKjcx1YHMd3EqzK47+mNM9TODczOyC3TD7TxsArQaJv3tFZnGcvB0sPQk12bjwnFo5ndtbmHzTWKeifTAIgzlSVmn3RWcLfZyt7Ni4azGKZoFNEm5IXj4yrx98IAzmaNfKDGdvh+pj7gbJ1c/x1unXz+IluAv5B4TB7MT+lOvkZU9lmG+vi6G4+DpePV5cVmwudyOAMJiXpOtliMLgChrLeeZNA5qc3VWIuwoChMG8XD9RbOvWiC6/pDEpJCot5VY57kIQhMG83D5d4uRhQ2pk/yeC5rY3T5bUY0Gjw/DGS6XSNd8vHTy026Ilc2OPHezTr73pazBHOpR2X2Lrysddx1ut2zL6j9MbDb5aCo1sI7RKu4e/pxVDGJKSHl64cCZ88vTPw2d+5KqOHT+0dl0DGeAk+7mcxqSSyCTchWDA5LKeJUpxV4FlzyCTIoT69hvcooXnR64q7ckjAxWF34tkCcumsbSba+HaszPT8IfBYD3ZQz/pIZoc8fe1i8nJCadPXmOz2Wf+OnHy1LFXr164u3v26tl/RNgYhND2X388eGg3Qih0WK8OHboEBXaouZI6n4IQ0mg0hw7v2b3nNxKJ1Ka1n2hyRJs2frPmTElJSUQInT9/eudvB93dPQz1WrAoK1Jb2Rnrji0ajfrMha2Pn94sLy90bx7QOWSUd8uOCKGcvKebtk6YPS3m0tXfH6Vds+Y7+vv0Hdw/Uj+yW37hy4OxKwqLX3k0D+zTI9xItSGESCTk2Jyb80IhbIHz5FaD7RlodPqx4wc9Pb3XR29lMBgXLpyJXr/S26v1gX0nRZMjDh/Zs3XbJoTQtKmzlyxehRA68cfltas311zD256ij9DJk7ErV2xYsmiVncB+waJZ2dmZ/9uys1Urn379Bl+5FGfpSUAI5b+SU+nG2lHHnlx3486hrh0+XTL/hI93d/H+r1IeX0UIUal0hNCRP9YEth34/bIbY8KW/X1zb2LKJYSQWq3asXuuNd/hq1kHB/aZfvnarkqJEZu5KqVWWo75tgQGe/cpFIrA3mHWzKjAdiEUCuXk6WN+fgFzZi+wtrYJCmw/aeLUY8cPlpe/a2Setz2lrOz1kaP7xoyZFBzUoUuXHl/N/zbAP7ikpNhQlZsDrUanVmkpNKOEQalUPIg/06vrpI4hYWw2r31QqL9v3wtXdiKEyCQyQqitT28/n15UKs3DPdDG2ik7Nw0hlJx6pay84JOBX9pYOzk7eYQOmqdQGPHXYgqNKqvAfNGVId/9lp6t9A/UanVqanJwUMfqWQEBwRqNJjk54W3PfcdTXqY/Rwi1akXcPYBKpa5csb5t23YGrBw7abnaTmis05Aycx5ptOqWHv/02rVo3i4n74lCQRymuzRpVT2LyeTKFZUIoeKSLDqNaWvjrJ9uY+3E4xrxbmM0Fk2lNMXluBwOh82u+6025NkvdDpx2bRCodBoNDtjtu6M2Vpzgddlb72f5DueotVpEUJsVsM8ZU2Pwaa8zpc7GefyY/03+s87ptaaXlFZrG8bkOr6aUMmr2Ay/zVQEJ1uxPa9Uq6uswyDk0rf2lI3yqlgVlZWTCZzQP+h3br1rjld2MT1A56SlZ2BEKqUVBqjVDNBZ5J1OqTV6MgUw3etcq3sEEIjQxcJbP/1/vP5DhUVRW97FpvFU6mqak5RVBmxw0ejUnP4mL/vjHVepLu7p1whD/AP0v+pVCoLCvIcHBw/4ClMFotCoSQmPmjl3UY/5NvCRbP79hnUt+8gIxWPBZtLVSs1xrh0wUHQlEqlk8kUD3diqLyKyhISicR45ze9jbWzXFFZUJju6NAcIZSZ/UgiMeKNorVqDYeP+SxdY+2Ypn0x+9q1S2f+OqHRaJKS4r9buXD+V9OVynedn/i2p/C4vH59B584ceSvs3/GJ8T9+L8f4hPiWrX2RQgJha5PnqTGJ8SVlVn8uGD2Qoa8vKoeC743Fovbr9cX5y//9jIjQalUJKZc2i6eefzU+nc/q02rblQq/ciJtUqloqy88EDsd2yWEe/VLX1d5eCC+do3Y4XBzy9g+7a9SUnxw8P6fL0wUi6TrVq5sbpR8b5PmTN7gb9/0IaNq+fNj0hNTV65YoOL0BUhNHRwmE6ni/pqRvqrF0Z6ISbj6c+RlhrrOKRX14mjhi25cn33t6t7/3F6g71909HDlrz7KSymVfhnG5RK+Tere63/35junccJ7NwQMkobV1ZWxRfQmRzMZ62TdLo6Xt7dv0pVKtS2uy2OkoxLqdDGbnk1dY077kJqU1Vpd3yb3qpnM9yFYFD44nVzL3JwX1N83n799VeE0NSptbsT4KxVM0JjkJu25lYWm9eVkKahqFC0DsZ/hmJDvrDQ4nQeYnPkxxyu4K19bt+s7l3ndI1GTSFTEKnunqgl80+wmAYbTf33/V8/T39Q5ywux7ZSWncje9WSS29bYWlWhasng2ON/8o+CIMZ4Qtori3ZpTmVtkJunQvMm7HnA1ZrwCQghMKGfK3W1N0RolQq6PT3Prko72lJ6PctDFHax4IwmJd+nzmIV2TYOHPr/AHK1qYJhpr+jccz5O/QRS9Ke4x0oFDN4sR1aDOYFxIJhc1o8vJeNu5CTKE0u8LOAbXpYMQe2/cCYTA71va0ARMdspMLcBdiXMUZ5Twrda/R9vVY1kQgDOZI2ILVe5Tti7vZxunWx68ko4xOruoz1oySAGEwX87NmWEzmjy5nlGWZ0bDbH08pVxdnF7q7II+meqMu5baIAzmy8aBNm2NO50kf3k3W1JimPswYKRVa/OeFGcn5QV2ZXcaYoe7nDpAb5J5I6FBIqeSPOWNkyVPHxda2bG59hy2NYNCtYxvMZ1Wp1Joygul0hIpy4rSJojj1+VdJ2viBWGwAHbO9NCpztJy9ctk6dP4iqIXKrlERWdR+QKmXGKmt/HVqDRKhUaj1jo14zgK6Z4D7M3/5j0QBovB4VN9u/B9u/ARQhq1TlqhkUs0Oq2ZNrHpTDKbR7Wse8ZCGCwShUri2VJ5tvDfZ0h1B5fJISOz+E3Q8DQqnZ2z2d0zBpiDusNg40gvyrT47os6Fecq6CxL2ncDk6n7Y+Hakq2QqRXSBni/5Kwn0lbB5vL7PzArdYeBREL9xjtdi83XqM20ffZh7p0ttnagerTl4C4EmKO3tsDsnOm9RtsfWPeyVXtrvoBuWd0CtZDIqDinSlapYbJJ7fs3wMv3gEG8qzvCxpE+/YcWSTfKi3PkUmOOdpadlS2wFzCZxuqHtrKhsK2obdpzhR7m3tUNMPrvvjm/Lka/Hk8kWjxv1Dxf3+bG3hAA72DBBz8AGBaEAQAChAEAAoQBAAKEAQAChAEAAoQBAAKEAQAChAEAAoQBAAKEAQAChAEAAoQBAAKEAQAChAEAAoQBAAKEAQAChAEAAoQBAAKEAQAChAEAAoQBAIJZhEGprPu+wgAYnFwuf9ssswjDrFmzZsyYERMTg7sQ0JBlZ2evWrXq5MmTI0eOrHMBswhDhw4dzp8/r1AogoODt27d+o7sAvABnj9/vmTJksjISB8fn4sXL9ra1j3EKEmnM6+hhWNiYsRicWhoaHh4+NuKBqCekpOTxWJxXl7e5MmT+/fv/+6FzS4MegcPHoyJienatWt4eLhQKMRdDrA89+7dE4vFCoVCJBJ169atPk8x0zDonThxQiwWt2nTRiQSeXh44C4HWIarV6+KxWI2my0SiYKDg+v/RLMOg9758+djYmKcnZ1FIpGfnx/ucoD5Onv2rFgsdnFxCQ8Pb9Omzfs+3QLCoHf9+nWxWEyn08PDw0NCQnCXA8zLsWPHxGJx27ZtRSJRixYtPmwlFhMGvbi4OLFYLJFIwsPDu3fvjrscgN/+/ftjYmJ69eolEomcnZ0/ZlUWFga9R48excTEZGVliUSigQMH4i4HYKDRaMRisVgsHjlypEgksra2/vh1WmQY9F6+fCkWi+Pj48PDw8PCwnCXA0xEKpXGxMTs3btXJBKJRCIGw2A3MrbgMOjl5+fHxMRcvnxZJBJ99tlnuMsBRlRUVCQWi8+cOSMSiSZNmmTw9Vt8GPTKy8tjYmKOHj2q/7agUCi4KwKGlJmZKRaL79y5IxKJRo8ebaStNJAw6FVVVemPI8ePHx8eHs7hwC1uLd6TJ09iYmKePXsmEomGDh1q1G01qDBU2717d0xMzKBBg0Qikb29Pe5ywIdISEgQi8UlJSUikah3794m2GLDDIPe4cOHxWJx+/btw8PD3dzccJcD6uvWrVtisVin04WHh3fq1Mlk223IYdA7depUTEyMp6dneHi4l5cX7nLAu1y+fDkmJsbW1lYkEgUEBJh46w0/DHqXLl0Si8V2dnYikcjf3x93OaC2U6dOicViDw8PjN9ZjSUMerdu3YqJiSGRSCKRyJT7X/AOR44ciYmJad++vUgkatq0KcZKGlcY9OLj48VicWlpaXh4eK9evWrN7du374ULFzCV1rjo+zkGDhwYHh5uDv0cjTEMemlpaWKx+Pnz5+Hh4YMHD66eHhAQIBQKDxw4wOVysRbYYCmVSrFYHBMTM378eJFIZGVlhbsiQuMNg15GRkZMTMz9+/dFItGoUaMGDhxYVFSk0+natm0L12QbnP630SNHjohEovDwcHP7bbSxh0GvsLBQLBb/9ddfFRUVZDIZIUSlUkeMGPHVV1/hLq2BsIizZiAM/xg8eHBBQUH1nzY2NnPmzBkyZAjWoiyeBZ1PCWH4R1BQUK0prq6uGzZscHd3x1SRZbO4M+0bfhhkFZrSAqW0XK195yuNjo6urKysNVGn09na2n755ZdGrrGhUSgUhw8frqqq6tq1q7e393s9l0ol8+1oAhcG2eTDGDXwMNw4UZzzQk6lk60FdJXqXa+0sqICIYQQiUQi6ZAOIURCJIQQiYQ4ZtPdYSk0ao1Wp6XRaB/wXLYVJfeljM4k+3TktWxn0g69hhyGSweLmFZUv642uAsBH+LS/rw2HXme/qY79dgsRtQzhhsnihlsCiTBcvUe55x4tSzrqemGV2yYYZBVaHJfKtp2hwH5LFvIQPuEq2Um21zDDENJXhWVTsJdBfhYfAE984nUZJtrmGGoLFNb2xvsOnGAC5mCbBwY0gqNiTZnms2Ymg6plFrcRQADUEjUJtvFN9AwAPD+IAwAECAMABAgDAAQIAwAECAMABAgDAAQIAwAECAMABAgDAAQIAwAECAMlmH1mm9mzZlipJUfObqv34CO9Z/eUEEYAGrdynf8Z0TSjh0/tHbdsjenNwZU3AUA/Nq08WvThrjBdtqTRyQS6c3pjQGEgTD0kx6iyRF/X7uYnJxw+uQ1NpudnJywa/evT56k2toJOrTvMnnSNBaLhRAqryjftWv7nTs3yivKvFq27tt30MABn+hXcuavEydPHXv16oW7u2evnv1HhI3RT5dIJEeO7r1379arjJe2toIunXuIJkcwmcw6t3vz5tX//RxdVFTo0aJl2PAx/fsTAzfRqLT4hLjVa74pLy/z8PCaO2ehV8tW//m66lxbrY2ePnP8tx0/nT97e9acKSkpiQih8+dP7/zt4IOHd/XTEUIymWz12m8ePryn0WgiZ0bl5eXcuXtDvPPwo0dJkbPDt/68q5U3cRPyMeOG9OzRb9rU2Qih4uKirds2PkpNqqqqCgnpNGniVGETF6P9H34sOEwi0Oj0Y8cPenp6r4/eymAwMjNffb0wUqVWbf1517Jvv3/2LG1eVIRWq0UIrV+/Mu1J6pdfLo7ZcdjLq3X0+pWpj1MQQhcunIlev9Lbq/WBfSdFkyMOH9mzddsm/cqPxu7ff+D3MWMmrVm9OWLanEuXz+7dt7PO7d68eXXZd19/PiVyzerNnTv3+P6H5ZevnNcvWViYf/r08SWLV32/9seqKsUP0d/954t629pqbbR6+f9t2dmqlU+/foOvXIpzd/eouaqNm9e8Sn+xZfOOg/tPvcp4efnKORr1Pwa/UKvV86IiklMSouZ/K955mMvlTZ8+IS8/9/3/c0wE9gwECoUisHeYNTNK/+fFS3/RqLQVy6P5fGuE0Pz534yfMOzW7WtdOvdITHr42ThRcFAHhNC0qbO7d+9jY22LEDp5+pifX8Cc2QsQQkGB7SdNnLpx05rPxon4fOsxn07s2aNv06bN9StPTHx4//7tz6fMfHO7Mb9v69a1V5/eAxBC7UM6SSSVMhlx3WNhUcG2bXu4VlyE0PBhn27ctKZSUqn/823etrZaG/1PEonk6tWLkTOjWnp6I4QiZ8y/e+fGf46rkpj0MCsrY8P6be0CghFCM6fPu33rWmzsgciZ8+u5XRODMPyjpec/Rx0pKYne3m30SUAICZu4ODk6JyY+7NK5h6+v/4GDu0pLSwL8g4KCOnh7tdZ/C6amJk+eNK16DQEBwRqNJjk5oUuXHjQa7d79W2u/X/ri5TO1Wo0QEgjs39yuRqNJT38xoP8/t/GbMf2f8ctatGhZ/dHn8fgIIWVVFXp7GN69tpov9j9lZqar1epWrXz0f5LJZG/vNhmZ6e9+VnJyAo1G0ydB/yy/tu2Sk+Prv10TgzD8g06nVz+WSCqfPX/Ss/e/Bpx8/boEIbTg6+V//nn00uWzh4/steJYhYWNmTD+c4VCodFodsZs3Rmz9V9PKStFCG39ZdOFC2emfjGrfUhne3uH7b/+ePHSX29uVyqT6nQ6FotdZ3lU6j//WdVt3Hd499pqvtj/VFpaghBi11jV21Zbk0RSqVKpar2HdnaC+m/XxCAMdbO1E/iyWKLJETUn8nnWCCEelzf+s/DPxolSUhKvXb+8e88OHpc/YsRYJpM5oP/Qbt3+dV9KYRNXrVZ75swfo0eNHzJ4uH6iRFJ7HEs9NotNIp6mENsAAAP/SURBVJHeNvd9GXBt+j2kQqGonlJ98PYmjYa4ft/OTsBisVav2lRzLpVivh85860MrxbunleunPdvG1j9Hfzq1UsXF7fy8rJLl88NHjSMwWD4+vr7+vo/ffb42YsnCCF3d0+5Qh7gT3wRKpXKgoI8BwdHhUKhUCjs7Ijjoqqqqtt3rtf51U6lUj09vBKTHo75dKJ+yi/bt+h0uukRcz/gJRhwbU5OTRBCqY+TPTxaEseEj5OtrLj6tjhCSKEghvqqqKzQ70aIN0Qud3Jq4uzURD8lJzfb1sbuA16LaUBvUt1Gj56g1qh/2rpBoVBkZr76ZfuW8M8/zchIJ1MoYvG25SsWPHqU9Pp16blzp549S/Np0xYhNO2L2deuXTrz1wmNRpOUFP/dyoXzv5quVCqZTKZQ6Hr23Mmc3Ozy8rJ1Pyz38w2oqCiv+UVbLWz4mPv3bx86vCc+Ie6PE0cOH9nr3tyjrgLr5QPWJhS6PnmSGp8QV1b2unqivb2Dj0/bnTFbc3KzCwryN21eK5VK9LOaNXXnWnHPnT+lD8n365ZxuTz9rPYhnUJCOkVHrygoyC8re33s+KGIiPH6Jc0T7Bnqxufxd+44dPDgrs+njs3JyfL2brPgq2UtWngihFat3Pi/n6MjZ4cjhNzdPSJnRul/Z/DzC9i+be++/eJfftmsVClbt/JdtXKj/tB86bdrf966YbJoJJPBjJwZ5ePrfz/udujwXvv3/llru/37D6moLN+1+1epVGpnJ5geMbf6d4YP8AFrGzo4bMOm1VFfzVgf/a/Gz6KFKzZvXvv5F2MUCkXvXv27dun19Nljfdvj22/XbvlxXc/eQfb2DhHT5paWFFd3NK1dvfnPk7ErVi1KTU12c2s2cGDosNBRH/xyjK1hDjyceqci67mi01AH3IU0WBs2rn6clrLj1wPG3tCRDeljotzYPFPc8AoOkwAgwGGSZRsW1kejVtc5a/GilR07djV5RRYMwmDZtm3d/bZZ+t/FjWT+vCXGWzkuEAbLVt1rCT4etBkAIEAYACBAGAAgQBgAIEAYACBAGAAgQBgAIEAYACBAGAAgNMww0NlkChXuA90QcKypNIaJPqUNMwz2TRi5z2W4qwAfq7JUVSXX0hgm+l5rmGHgC2jWDrTSfCXuQsBHyXwibRXCM9nmGmYYEEL9PnO6c6pAVlH36c3A/D19WFGSKw/ua2OyLTbMK9305BLNwfWZHgF8Dp/Ks6FrtFrcFYH/RqGQSvKqqmSaihLlkM+dTbnphhwGveRbFYWZCoVMq1RocNcC/hvXlspgUpo0Z7VoyzHxpht+GACopwbbZgDgfUEYACBAGAAgQBgAIEAYACBAGAAgQBgAIPwfy6xT3NAcfwsAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(graph.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "98f3be1d-cc4c-41fa-9863-3e386e88e305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'planner': {'plan': 'Title suggestion\\n- ‚ÄúLangChain vs. LangSmith: What They Are, How They Differ, and When to Use Each‚Äù\\n\\nThesis (one-sentence)\\n- LangChain is a developer framework of composable building blocks for creating LLM-powered applications; LangSmith is a complementary observability/evaluation platform (and associated tooling) that helps you test, trace, debug, and monitor those applications ‚Äî so one is for building and the other is for operating and improving.\\n\\nTarget audience & tone\\n- Audience: engineers, technical product managers, ML/AI practitioners evaluating tooling for LLM apps.\\n- Tone: clear, technical but accessible, pragmatic. Use concrete examples and short code snippets only if needed.\\n\\nSuggested total length\\n- 1,200‚Äì1,800 words (adjust per publication). Provide diagrams/tables for quick comparison.\\n\\nOutline with notes/instructions\\n\\n1. Introduction (100‚Äì150 words)\\n   - Purpose: explain why comparing these two tools matters (rise of LLM apps; need for both composition and observability).\\n   - One-sentence thesis (use the sentence above).\\n   - Quick roadmap of the essay.\\n\\n   Notes: Start with a concise motivating example (e.g., a chatbot that started hallucinating after a model change) to show why both building and monitoring matter.\\n\\n2. Background / Definitions (150‚Äì250 words)\\n   - Define LangChain: origin, primary goal (framework for composing prompts, chains, agents, memory, document retrieval, vectorstores, etc.), languages supported (Python/JS/TS, etc. ‚Äî verify current list).\\n   - Define LangSmith: origin (product from LangChain team), primary goal (run-tracking, debugging, evaluation, dataset labeling/management, model comparison, observability), basic components (dashboard, SDK/agents integration, evaluation tools).\\n   - Emphasize that they come from the same ecosystem and are designed to interoperate.\\n\\n   Notes: Cite official docs/blog as sources if publishing. Keep the definitions crisp and non-technical high level.\\n\\n3. Core purpose and positioning (200‚Äì300 words)\\n   - LangChain: building blocks for LLM app development\\n     - Prompts, prompt templates, chains, agents, memory, retrievers, connectors (databases, vectorstores), output parsers, callbacks.\\n     - Focus on orchestration and composition.\\n   - LangSmith: tooling for observability, evaluation, and lifecycle management\\n     - Run tracking (input/output/metadata), debugging traces, evaluations, labeled datasets, metrics, A/B testing, model comparisons.\\n     - Focus on production readiness, iteration, and quality control.\\n   - Positioning comparison table (one-line rows): goal, primary users, product type (OSS library vs SaaS/platform/tooling), typical stage in workflow (development vs monitoring/iteration).\\n\\n   Notes: Recommend a short 2-column table or bullet list to make differences obvious.\\n\\n4. Technical comparison (300‚Äì450 words)\\n   - Integration and workflow\\n     - How LangChain code emits telemetry/callbacks that LangSmith ingests (instrumentation model, SDK hooks, run objects).\\n     - Typical workflow: build chain in LangChain ‚Üí instrument runs ‚Üí send to LangSmith ‚Üí analyze/evaluate ‚Üí iterate.\\n   - APIs/SDKs and languages supported\\n     - LangChain: libraries (Python/JS), community modules and connectors.\\n     - LangSmith: SDK for run tracking, APIs for evaluations; possible UI for manual labeling.\\n   - Data captured and storage\\n     - What data LangSmith stores: inputs, outputs, intermediate steps, model metadata, environment, runtime metrics.\\n     - Privacy considerations: PII redaction and retention policies (recommend verifying current policies).\\n   - Observability & debugging features\\n     - Run visualizations, step-by-step traces, nested chain visualization, error annotations.\\n   - Evaluation & dataset management\\n     - Creating test suites, human-in-the-loop labeling, automated metrics, model comparisons and A/B tests.\\n   - Extensibility & plugins\\n     - LangChain‚Äôs extensible modules vs LangSmith‚Äôs ability to plug into non-LangChain code (if supported‚Äîverify current capabilities).\\n\\n   Notes: Where APIs change often, add a reminder to check latest docs. Suggest including a small diagram of dataflow (LangChain app ‚Üí LangSmith SDK ‚Üí LangSmith UI).\\n\\n5. Practical considerations (pricing, deployment, security) (150‚Äì250 words)\\n   - Licensing and cost model\\n     - LangChain: open-source library (free); potential running costs for model calls, hosting, vector DBs.\\n     - LangSmith: typically SaaS / paid tiers for advanced features ‚Äî verify current pricing and free tier availability.\\n   - Deployment and hosting\\n     - LangChain runs wherever your code runs (serverless, VMs, containers).\\n     - LangSmith is hosted (SaaS) ‚Äî discuss on-prem or enterprise options (verify current offerings).\\n   - Data governance, privacy, and compliance\\n     - Discuss what to consider when sending data (user messages, PII) to a cloud platform.\\n   - Vendor lock-in and portability\\n     - Using LangChain keeps code portable; depending on LangSmith features may create operational dependency; mitigations: local logging, export APIs.\\n\\n   Notes: Strongly recommend verifying up-to-date pricing and enterprise features from vendor.\\n\\n6. Typical use cases and example scenarios (150‚Äì250 words)\\n   - When you need LangChain only\\n     - Prototyping, research, building end-to-end apps where simple logging suffices.\\n   - When you need LangSmith\\n     - Production apps where you need systematic evaluation, model comparisons, detailed debugging of agent reasoning, or compliance-quality tracking.\\n   - Combined scenario (recommended): Build with LangChain + instrument with LangSmith for full lifecycle (example: customer support assistant ‚Äî retrieval + answer generation; use LangSmith to track hallucination rate and compare models).\\n   - Short concrete example snippets (pseudo-code outline):\\n     - Example: instrumenting a LangChain chain with LangSmith run tracking (describe at high level).\\n\\n   Notes: Use real-world problems (hallucination, latency regressions, prompt drift) as motivators for LangSmith.\\n\\n7. Pros and cons (bullet list) (100‚Äì150 words)\\n   - LangChain pros: rich building blocks, active community, extensibility, multi-language support.\\n     Cons: you must build your own observability/eval unless you add tooling.\\n   - LangSmith pros: rich observability and evaluation features, helps production QA, designed to integrate with LangChain.\\n     Cons: SaaS costs, potential data residency concerns, may require instrumentation changes.\\n\\n   Notes: Be balanced and pragmatic.\\n\\n8. Decision guide / When to choose which (100‚Äì150 words)\\n   - Quick checklist:\\n     - If you‚Äôre just prototyping or need an OSS framework: start with LangChain.\\n     - If you need robust run-tracking, labeling, evaluations, or debugging at scale: add LangSmith.\\n     - For production apps: default to LangChain + LangSmith (or equivalent) for both building and operating.\\n   - Suggest evaluation steps: pilot project, cost estimate, data compliance check, measuring ROI.\\n\\n   Notes: Provide a short decision flow (three questions) that maps to recommendations.\\n\\n9. Adoption and migration notes (100‚Äì150 words)\\n   - Instrumentation approach: start with sampling, then expand.\\n   - Data retention/export: ensure you can export runs/datasets for backup or to avoid lock-in.\\n   - Team roles: developers use LangChain; product/QA/ML engineers use LangSmith dashboards and evaluators.\\n   - Integration tips: use callbacks/hooks to minimize code changes; use CI to enforce test suites.\\n\\n   Notes: Suggest gradual rollout and a proof-of-concept with a small dataset.\\n\\n10. Conclusion (50‚Äì100 words)\\n   - Reiterate core difference: LangChain = build, LangSmith = observe and improve.\\n   - Practical takeaway: they are complementary; production-grade LLM apps benefit from both.\\n\\n11. Further reading & sources to consult (brief list)\\n   - Official LangChain documentation and GitHub repo.\\n   - Official LangSmith docs / product pages (and blog posts announcing features).\\n   - Community tutorials / examples that show LangChain + LangSmith integration.\\n   - Papers/articles about LLM app observability & evaluation.\\n\\n   Notes: When publishing, link to the latest docs and explicitly note the date, because features change fast.\\n\\nOptional appendices (if longer essay desired)\\n- Appendix A: Example instrumentation code (LangChain callback ‚Üí LangSmith SDK).\\n- Appendix B: Checklist for production readiness (evaluation metrics, logging, alerts).\\n- Appendix C: Comparison table of specific features (prompts, tracing, dataset management, model comparison, pricing tiers).\\n\\nFinal writing instructions\\n- Use at least one small diagram (dataflow) or a two-column comparison table.\\n- Include 1‚Äì2 short real-world examples to make the abstract differences concrete.\\n- Verify up-to-date product details (pricing, on-prem options, SDK support) at time of publication.\\n- Keep jargon explained briefly; include links for deeper technical references.\\n\\nIf you‚Äôd like, I can convert this outline into a full essay draft, produce the comparison table and a sample instrumentation code snippet, or update specific claims after you supply the current LangSmith/LangChain doc links. Which would you prefer?'}}\n",
      "Search results for query 'LangChain vs LangSmith differences ‚Äî purpose, features, use cases, official documentation and blog posts': [{'url': 'https://blog.promptlayer.com/langchain-vs-langsmith/', 'title': 'LangChain vs LangSmith: A Developer-Focused Comparison', 'content': 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangChain streamlines the development of conversational agents and tool-using AI. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', 'score': 0.8396422, 'raw_content': None}, {'url': 'https://orq.ai/blog/langchain-vs-langsmith', 'title': 'Langchain vs Langsmith: Framework Comparison + ...', 'content': 'Compare LangChain, LangSmith, and Orq.ai to discover the best LLM development tools for building, deploying, and optimizing scalable AI applications. As a comprehensive platform for LLM product development, LangChain equips software teams with the tools needed to build, test, and deploy LLM-powered solutions at scale. While LangChain focuses on the flexibility and modularity required for building LLM-powered applications, LangSmith steps in to offer essential tools for deployment, monitoring, and optimization throughout the production process. Orq.ai offers several advantages over LangChain and LangSmith, providing a more integrated and efficient solution for LLM development. By offering an integrated solution that supports the entire LLM development lifecycle, Orq.ai enables teams to seamlessly build, deploy, and optimize LLM applications at scale, without needing to juggle multiple specialized tools.', 'score': 0.8025714, 'raw_content': None}]\n",
      "Search results for query 'What is LangChain: architecture, components (chains, agents, memory, tools, connectors), typical workflows and examples': [{'url': 'https://python.langchain.com/docs/concepts/architecture/', 'title': 'Architecture', 'content': \"ü¶úÔ∏èüîó LangChain ü¶úÔ∏èüîó LangChain LangChain is a framework that consists of a number of packages. ## langchain-core\\u200b The main `langchain` package contains chains and retrieval strategies that make up an application's cognitive architecture. `langchain` `langchain-openai`, `langchain-anthropic`, etc) so that they can be properly versioned and appropriately lightweight. `langchain-openai` `langchain-anthropic` ## langchain-community\\u200b This package contains third-party integrations that are maintained by the LangChain community. This contains integrations for various components (chat models, vector stores, tools, etc). `langgraph` is an extension of `langchain` aimed at building robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph. `langchain` A package to deploy LangChain chains as REST APIs. Makes it easy to get a production ready API up and running.\", 'score': 0.752468, 'raw_content': None}, {'url': 'https://lakefs.io/blog/what-is-langchain-ml-architecture/', 'title': 'What Is LangChain: Components, Benefits & How to Get ...', 'content': 'LangChain is an open-source framework that gives developers the tools they need to create applications using large language models (LLMs). LangChain offers a number of tools and APIs that make it simple to link language models to external data sources, interact with their surroundings, and develop complicated applications. The primary use case for LangChain at the moment is chat-based apps on top of LLMs (particularly ChatGPT), also called ‚Äúchat interfaces.‚Äù In a recent interview, the company‚Äôs CEO Harrison Chase, said the ideal use case right now is a ‚Äúchat over your documents.‚Äù LangChain also provides additional features to improve the conversation experience for applications, such as streaming, which implies providing the output of the LLM token by token rather than all at once.', 'score': 0.7334523, 'raw_content': None}]\n",
      "Search results for query 'What is LangSmith: features for evaluation, monitoring, debugging, observability, pipelines and how it integrates with LangChain (official docs, tutorials, comparisons)': [{'url': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith - LangChain', 'content': 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith # Get started with LangSmith **LangSmith** is a platform for building production-grade LLM applications. LangSmith + LangChain OSS For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph. LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith‚Äôs observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production. The LangSmith SDK and UI make building and running high-quality evaluations easy. - Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.', 'score': 0.7557276, 'raw_content': None}, {'url': 'https://www.ibm.com/think/topics/langsmith', 'title': 'What is LangSmith?', 'content': \"While LangChain helps you build workflows, LangSmith helps ensure that they run smoothly by offering tools for debugging, monitoring and managing complex AI systems. LangSmith operates by embedding itself into the LLM application stack, whether you're using LangChain or building custom pipelines to provide visibility, traceability and control at every stage of development and production. Factory, a company building AI agents to automate the Software Development Lifecycle (SDLC), uses LangSmith to help ensure secure, reliable LLM operations in enterprise environments. LangChain is well suited for designing and prototyping complex language model workflows, enabling seamless integration with external tools and APIs. Use LangSmith when you're ready to move into production and need robust tools for debugging, testing, monitoring and maintaining LLM applications at scale.\", 'score': 0.7515939, 'raw_content': None}]\n",
      "{'research_plan': {'content': ['In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangChain streamlines the development of conversational agents and tool-using AI. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', 'Compare LangChain, LangSmith, and Orq.ai to discover the best LLM development tools for building, deploying, and optimizing scalable AI applications. As a comprehensive platform for LLM product development, LangChain equips software teams with the tools needed to build, test, and deploy LLM-powered solutions at scale. While LangChain focuses on the flexibility and modularity required for building LLM-powered applications, LangSmith steps in to offer essential tools for deployment, monitoring, and optimization throughout the production process. Orq.ai offers several advantages over LangChain and LangSmith, providing a more integrated and efficient solution for LLM development. By offering an integrated solution that supports the entire LLM development lifecycle, Orq.ai enables teams to seamlessly build, deploy, and optimize LLM applications at scale, without needing to juggle multiple specialized tools.', \"ü¶úÔ∏èüîó LangChain ü¶úÔ∏èüîó LangChain LangChain is a framework that consists of a number of packages. ## langchain-core\\u200b The main `langchain` package contains chains and retrieval strategies that make up an application's cognitive architecture. `langchain` `langchain-openai`, `langchain-anthropic`, etc) so that they can be properly versioned and appropriately lightweight. `langchain-openai` `langchain-anthropic` ## langchain-community\\u200b This package contains third-party integrations that are maintained by the LangChain community. This contains integrations for various components (chat models, vector stores, tools, etc). `langgraph` is an extension of `langchain` aimed at building robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph. `langchain` A package to deploy LangChain chains as REST APIs. Makes it easy to get a production ready API up and running.\", 'LangChain is an open-source framework that gives developers the tools they need to create applications using large language models (LLMs). LangChain offers a number of tools and APIs that make it simple to link language models to external data sources, interact with their surroundings, and develop complicated applications. The primary use case for LangChain at the moment is chat-based apps on top of LLMs (particularly ChatGPT), also called ‚Äúchat interfaces.‚Äù In a recent interview, the company‚Äôs CEO Harrison Chase, said the ideal use case right now is a ‚Äúchat over your documents.‚Äù LangChain also provides additional features to improve the conversation experience for applications, such as streaming, which implies providing the output of the LLM token by token rather than all at once.', 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith # Get started with LangSmith **LangSmith** is a platform for building production-grade LLM applications. LangSmith + LangChain OSS For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph. LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith‚Äôs observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production. The LangSmith SDK and UI make building and running high-quality evaluations easy. - Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.', \"While LangChain helps you build workflows, LangSmith helps ensure that they run smoothly by offering tools for debugging, monitoring and managing complex AI systems. LangSmith operates by embedding itself into the LLM application stack, whether you're using LangChain or building custom pipelines to provide visibility, traceability and control at every stage of development and production. Factory, a company building AI agents to automate the Software Development Lifecycle (SDLC), uses LangSmith to help ensure secure, reliable LLM operations in enterprise environments. LangChain is well suited for designing and prototyping complex language model workflows, enabling seamless integration with external tools and APIs. Use LangSmith when you're ready to move into production and need robust tools for debugging, testing, monitoring and maintaining LLM applications at scale.\"]}}\n",
      "{'generate': {'draft': 'Title: LangChain vs. LangSmith: What They Are, How They Differ, and When to Use Each\\n\\nIntroduction\\nImagine you ship a customer-support chatbot built on an LLM. It performs well in tests, but after switching to a newer model you start seeing subtle hallucinations and longer tail failures. Your prompts and retrieval code look fine, but you don‚Äôt have a systematic way to inspect intermediate reasoning, compare model outputs across versions, or roll back quickly. That gap is exactly why comparing LangChain and LangSmith matters. Thesis: LangChain is a developer framework of composable building blocks for creating LLM-powered applications; LangSmith is a complementary observability/evaluation platform (and associated tooling) that helps you test, trace, debug, and monitor those applications ‚Äî so one is for building and the other is for operating and improving. This essay explains what each product is, how they fit together in a typical LLM app lifecycle, the technical differences that matter to engineers and product managers, and a short decision guide for when to adopt each.\\n\\nWhat they are and how they‚Äôre positioned\\nLangChain is an open-source framework (Python and JavaScript/TypeScript are first-class) focused on composition: prompt templates, chains (pipelines of calls and transformations), agents (tool-using decision-makers), memory (state), retrievers and vector store connectors (for retrieval-augmented generation), output parsers, callbacks, and community integrations. Its job is to make it straightforward to orchestrate LLM calls, tie LLMs to external data sources and tools, and iterate on application logic and prompts. LangSmith is a product (from the same creator team) that targets the operational side: run-tracking, rich traces of inputs/outputs/intermediate steps, labeling and dataset management, off-the-shelf evaluators and custom evaluators, model comparisons and A/B testing, and a web UI for exploring runs and debugging failures. High-level positioning comparison:\\n- Goal: LangChain = compose LLM workflows; LangSmith = observe, evaluate, and improve runs.\\n- Primary users: LangChain = engineers building features; LangSmith = engineers, ML/QA, product managers evaluating quality.\\n- Product type: LangChain = OSS library; LangSmith = managed observability/evaluation platform (SaaS with SDKs).\\n- Typical stage: LangChain = development/prototyping and production logic; LangSmith = instrumenting, testing, and running in production for quality control.\\nThey‚Äôre designed to interoperate: use LangChain to build chains/agents and add LangSmith instrumentation to capture runs for later analysis.\\n\\nTechnical comparison and typical workflow\\nIn practice you build the LLM flow in LangChain and insert instrumentation hooks or callbacks that emit ‚Äúruns‚Äù to LangSmith. A run can include the user input, prompt expansions, retrieved documents, the model‚Äôs token stream or final text, intermediate chain steps, model metadata, timing/latency, and custom tags/metadata (e.g., session id, user id hashed). LangChain exposes callback interfaces and run objects that LangSmith‚Äôs SDK can ingest; the typical workflow is: construct and test chains locally ‚Üí enable sampled or full run tracking via LangSmith SDK/callbacks ‚Üí view traces in the LangSmith UI, run automated evaluators, or queue human labeling ‚Üí iterate on prompts, rerun tests, or change models. Key technical points:\\n- SDKs & languages: LangChain supports Python and JS/TS as primary libraries; LangSmith provides SDKs or integrations to capture runs from those environments. Always check the repo/docs for the most current language coverage and examples.\\n- Data captured: LangSmith stores inputs, outputs, intermediate chain traces, model and environment metadata, timestamps, and evaluation labels/metrics. This detail enables step-by-step visualizations that show which chain step produced a bad output ‚Äî invaluable for debugging tool-using agents.\\n- Observability: LangSmith offers run visualizations (nested chain/agent traces), failure/error annotations, and aggregated metrics (e.g., hallucination rate, latency percentiles) often missing from ad-hoc logging systems.\\n- Evaluation: you get both automated metrics and human-in-the-loop labeling, dataset management for test suites, and model comparison tools to run A/B experiments.\\n- Extensibility: LangChain‚Äôs plugin and community integration model makes it easy to add connectors; LangSmith focuses on ingesting runs (including from non-LangChain code in many cases), evaluation plug-ins, and allowing custom evaluators.\\nA tiny pseudo-code outline of instrumentation:\\n- Create a LangChain chain as usual.\\n- Attach a LangSmith callback/agent that listens for run start/end and posts run objects to LangSmith.\\n- Run your chain; inspect runs in LangSmith UI for traces and evaluations.\\n\\nPractical considerations: cost, data governance, and use cases\\nLicensing and cost: LangChain is open-source (no license fees), but you still pay for model calls, hosting, vector DBs, and infra. LangSmith is typically offered as a managed product (free tier plus paid tiers historically), so expect SaaS costs for storage, advanced features or higher ingestion volumes; enterprise plans may include SSO, custom retention, or on-prem options depending on vendor offerings ‚Äî confirm current pricing and offerings before committing. Privacy and compliance: sending PII or user data to a hosted observability tool requires careful review of retention policies, redaction features, and contract terms. Mitigations include sampling (send 1‚Äì5% of runs initially), stripping PII client-side, hashing user identifiers, or self-hosting logs where possible. Deployment: LangChain code runs wherever you run your app (serverless, container, VM); LangSmith is hosted but usually provides APIs to export or delete data. Vendor lock-in: instrumenting deeply into a SaaS observability platform can create operational dependency ‚Äî mitigate by enabling run export, keeping local logs, and designing export-friendly tagging.\\nWhen to use each:\\n- LangChain alone: prototyping, research, and small projects where ad-hoc logging suffices.\\n- Add LangSmith: production systems requiring systematic evaluation, root-cause debugging, model comparisons, label-driven test suites, or audit trails.\\nDecision flow (quick): Are you prototyping only? Use LangChain. Do you need step-level traces, labeled test suites, or production QA? Add LangSmith. Want both build-time flexibility and runtime observability? Use both.\\n\\nAdoption, migration, and a short rollout strategy\\nStart small and iterate. Recommended rollout path: 1) Prototype the chain in LangChain without heavy instrumentation. 2) Add LangSmith instrumentation to a sampled subset of traffic to validate data flows and verify privacy controls. 3) Create focused evaluation suites (e.g., intents, factuality checks) and run A/B tests across model versions. 4) Expand coverage, add alerting on key metrics (latency regressions, hallucination spikes), and integrate labeling workflows for QA. Team roles: developers maintain LangChain code and unit tests; ML engineers/product/QA people curate evaluations and labels in LangSmith; ops/security own data governance and retention. Migration tips: use callbacks/hooks to minimize code changes, keep an export pipeline for runs/datasets to avoid lock-in, and run CI checks that execute evaluation suites before rolling new models.\\n\\nConclusion and further reading\\nCore difference in one line: LangChain helps you build LLM-powered applications; LangSmith helps you observe, evaluate, and improve those applications in production. In practice they‚Äôre complementary ‚Äî for production-grade LLM apps you‚Äôll usually want both: LangChain for orchestration and integration and LangSmith (or an equivalent observability/evaluation system) to track quality, debug failures, and compare models. Before adopting, run a small proof-of-concept: instrument a critical user flow, evaluate cost and data-residency implications, and measure how much faster you can iterate and detect regressions with run-level observability. For up-to-date details, consult the official LangChain and LangSmith documentation and community examples ‚Äî product features and pricing change rapidly, so verify current capabilities and enterprise options before making a procurement decision.', 'revision_number': 1}}\n",
      "{'reflect': {'critique': 'Overall assessment (grade): B+\\n\\nStrengths\\n- Clear, focused thesis: the central contrast (LangChain = build; LangSmith = observe/operate) is stated early and consistently supported.\\n- Logical structure: introduction, product descriptions, technical workflow, practical considerations, rollout strategy, and conclusion form a coherent narrative.\\n- Good coverage of the practical lifecycle (prototype ‚Üí instrument ‚Üí evaluate ‚Üí iterate), which is the most useful part for engineering teams.\\n- Includes relevant operational concerns (cost, privacy, vendor lock-in) rather than being purely feature-listing.\\n\\nAreas for improvement (high-level)\\n1. Evidence & specificity: the essay is high-level and conceptual. Engineers and product managers will want concrete examples, code snippets, screenshots or pseudo-output, and example metrics to act on.\\n2. Depth on trade-offs: some assertions (e.g., data governance mitigations, vendor lock-in, cost expectations) are generic; give specifics, trade-offs, and scenarios where the managed observability approach is not appropriate.\\n3. Audience clarity: the piece mixes guidance for prototyping engineers, ML/QA, and product managers. Decide whether this is a practical how-to, a product explainer, or a decision guide, and tailor depth accordingly.\\n4. Currency and sourcing: no references or dates provided. Products evolve quickly; cite versions, docs, or public examples so readers can verify features/pricing.\\n5. Visual organization: long blocks of text would benefit from tables, checklists, or diagrams (e.g., architecture + instrumentation flow).\\n\\nDetailed, actionable recommendations\\n\\nContent and structure\\n- Add a short executive summary (2‚Äì4 sentences) restating the thesis and the suggested decision flow ‚Äî helps busy readers.\\n- Create a concise comparison table (1 page or 200‚Äì300 words) listing key attributes side-by-side: supported languages, data captured, retention/export, on-prem options, pricing model, integration complexity, typical users, sample use cases. This makes the high-level differences scannable.\\n- Expand the ‚ÄúTechnical comparison and typical workflow‚Äù with a concrete, runnable code snippet (10‚Äì25 lines) showing how to attach a LangSmith callback to a LangChain chain in Python and a second example in JS/TS (or at least point to canonical examples). Readers appreciate copy-paste starters.\\n- Include a short worked example or mini case study (300‚Äì500 words) showing a real problem (e.g., hallucination spike after a model upgrade), how runs were instrumented, how a root cause was diagnosed in LangSmith, and what the fix looked like. Quantify improvements if possible (e.g., reduced error rate from X% to Y%).\\n- Add a short ‚ÄúWhen not to adopt LangSmith‚Äù section: for example, tiny hobby projects, budget-constrained teams, or extremely sensitive PII where any SaaS is disallowed (unless on-prem option exists). Explain the trade-offs for those cases.\\n\\nTechnical detail\\n- Provide a sample list of concrete observability/evaluation metrics and alerts to monitor: e.g., hallucination rate (how measured), extraction/intent accuracy, latency p95/p99, token cost per request, tool call failure rate, model drift indicators, label backlog, and SLA indicators. For each metric, list an alert threshold example and possible remediation steps.\\n- Specify what ‚Äúruns‚Äù mean in terms of data size/storage cost. Provide ballpark numbers or at least guidance: average run size (KB), indexing growth, and retention policy examples (e.g., full trace retained 30 days, aggregated metrics 12 months). If you can‚Äôt provide numbers, recommend how teams should estimate cost (sampling + retention targets).\\n- Expand the privacy/governance section with concrete controls and implementation suggestions: client-side PII redaction code patterns, token masking, hashing user IDs with salts, differential sampling strategies, encryption-at-rest and in-transit checks, and legal review checkpoints (DPA/BAA).\\n- Explain integration risks and mitigation in more detail: what parts of the app typically need code changes (callbacks, wrappers around LLM clients), how to run a canary rollout, and how to export runs for vendor-agnostic storage.\\n\\nStyle, tone, and audience\\n- Decide and state the primary audience at the top (e.g., ‚ÄúFor engineers and product managers evaluating production observability for LLM apps‚Äù).\\n- Reduce passive phrasing and aim for active voice. Shorten some paragraphs into bullet lists for scannability.\\n- Define any domain-specific terms the first time they appear (e.g., ‚Äúruns‚Äù, ‚Äúchains‚Äù, ‚Äúagents‚Äù, ‚ÄúRAG‚Äù).\\n\\nCitations and currency\\n- Add references/links to official docs and community examples. At minimum, include the date/version of LangChain and LangSmith features you refer to (e.g., ‚Äúas of June 2025, LangSmith supports X‚Äù).\\n- If you quote pricing or feature tiers, include a note to check current pricing and add links to the vendor pricing pages.\\n\\nLength and depth suggestions (targeted rewrite plan)\\n- Overall target length: 1,000‚Äì1,800 words for a practical decision guide version. If you want an authoritative technical whitepaper, 2,500‚Äì3,500 words including code, diagrams, and a case study.\\n- Suggested section word allocations for the 1,500-word version:\\n  - Executive summary + thesis: 100‚Äì150 words\\n  - What they are + positioning: 200‚Äì250 words (include the comparison table)\\n  - Technical workflow + code snippets: 300‚Äì400 words (include 10‚Äì25 lines of code)\\n  - Metrics, evaluation, and observability examples: 250‚Äì300 words (list metrics + alert examples)\\n  - Practical considerations (cost/governance/deployment): 200‚Äì250 words (include retention and privacy checklist)\\n  - Rollout strategy + mini case study: 200‚Äì300 words\\n  - Conclusion + refs: 50‚Äì100 words\\n\\nFormatting and visual aids\\n- Insert a small table comparing key attributes (as suggested).\\n- Add one simple sequence diagram or ASCII art showing: User ‚Üí LangChain chain ‚Üí Model + tools ‚Üí LangSmith callback ‚Üí LangSmith storage/UI.\\n- Use bold or heading-like lines to separate sections for easier skimming.\\n- Include short code blocks with commentary (not too long).\\n\\nAccuracy and balance\\n- Add a short paragraph on alternatives and ecosystem context: mention other observability/eval options (internal logging, open-source tools, or competitors) and when they might be preferable. This increases credibility and helps readers consider vendor lock-in rationally.\\n- Be transparent about limitations: for example, LangSmith being SaaS may have constraints for teams with strict in-country hosting requirements (unless an on-prem solution is offered).\\n\\nRevision guidance (practical steps)\\n1. Add an executive summary and a one-row comparison table.\\n2. Insert a 10‚Äì25 line Python example of LangChain chain instrumentation with LangSmith callback; optionally include a JS snippet.\\n3. Add a 300‚Äì500 word case study with a before/after outcome and concrete metrics.\\n4. Expand the privacy/governance section into actionable checklist items.\\n5. Add citations and ‚Äúlast checked‚Äù date for product claims.\\n6. Tighten language for scannability: convert at least half the longer paragraphs into bullets or numbered lists.\\n\\nQuestions for you (to guide the revision)\\n- Who is the primary audience for the final piece (engineers, technical leads, product managers, executives)?\\n- Do you have an example project or dataset you can use for the case study? If so, share details (anonymized) so the example can be concrete.\\n- Do you want runnable code included, or would pseudo-code suffice?\\n\\nIf you‚Äôd like, I can produce a revised draft that implements the above changes: I can add a comparison table, a Python + JS example for instrumentation, a 400-word case study, and a privacy/governance checklist. Which items should I prioritize?'}}\n",
      "{'research_critique': {'content': ['In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangChain streamlines the development of conversational agents and tool-using AI. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', 'Compare LangChain, LangSmith, and Orq.ai to discover the best LLM development tools for building, deploying, and optimizing scalable AI applications. As a comprehensive platform for LLM product development, LangChain equips software teams with the tools needed to build, test, and deploy LLM-powered solutions at scale. While LangChain focuses on the flexibility and modularity required for building LLM-powered applications, LangSmith steps in to offer essential tools for deployment, monitoring, and optimization throughout the production process. Orq.ai offers several advantages over LangChain and LangSmith, providing a more integrated and efficient solution for LLM development. By offering an integrated solution that supports the entire LLM development lifecycle, Orq.ai enables teams to seamlessly build, deploy, and optimize LLM applications at scale, without needing to juggle multiple specialized tools.', \"ü¶úÔ∏èüîó LangChain ü¶úÔ∏èüîó LangChain LangChain is a framework that consists of a number of packages. ## langchain-core\\u200b The main `langchain` package contains chains and retrieval strategies that make up an application's cognitive architecture. `langchain` `langchain-openai`, `langchain-anthropic`, etc) so that they can be properly versioned and appropriately lightweight. `langchain-openai` `langchain-anthropic` ## langchain-community\\u200b This package contains third-party integrations that are maintained by the LangChain community. This contains integrations for various components (chat models, vector stores, tools, etc). `langgraph` is an extension of `langchain` aimed at building robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph. `langchain` A package to deploy LangChain chains as REST APIs. Makes it easy to get a production ready API up and running.\", 'LangChain is an open-source framework that gives developers the tools they need to create applications using large language models (LLMs). LangChain offers a number of tools and APIs that make it simple to link language models to external data sources, interact with their surroundings, and develop complicated applications. The primary use case for LangChain at the moment is chat-based apps on top of LLMs (particularly ChatGPT), also called ‚Äúchat interfaces.‚Äù In a recent interview, the company‚Äôs CEO Harrison Chase, said the ideal use case right now is a ‚Äúchat over your documents.‚Äù LangChain also provides additional features to improve the conversation experience for applications, such as streaming, which implies providing the output of the LLM token by token rather than all at once.', 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith # Get started with LangSmith **LangSmith** is a platform for building production-grade LLM applications. LangSmith + LangChain OSS For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph. LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith‚Äôs observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production. The LangSmith SDK and UI make building and running high-quality evaluations easy. - Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.', \"While LangChain helps you build workflows, LangSmith helps ensure that they run smoothly by offering tools for debugging, monitoring and managing complex AI systems. LangSmith operates by embedding itself into the LLM application stack, whether you're using LangChain or building custom pipelines to provide visibility, traceability and control at every stage of development and production. Factory, a company building AI agents to automate the Software Development Lifecycle (SDLC), uses LangSmith to help ensure secure, reliable LLM operations in enterprise environments. LangChain is well suited for designing and prototyping complex language model workflows, enabling seamless integration with external tools and APIs. Use LangSmith when you're ready to move into production and need robust tools for debugging, testing, monitoring and maintaining LLM applications at scale.\", 'LangChain is the open, composable framework that provides a standard interface for every model, tool, and database ‚Äì so you can build LLM apps that adapt as fast as the ecosystem evolves. How do I use LangChain with other products like LangSmith, LangGraph, or LangGraph Platform? LangChain provides a standard interface for connecting models, tools, and data, then integrates seamlessly with any of the Lang- family products. Use LangChain when you need fast integration and experimentation; use LangGraph when you need to build agents that can reliably handle complex tasks. Can I use LangChain in production? Should I start with LangChain or LangGraph for building agents? Use **LangChain** for **composability and model flexibility**‚Äî great for quickly chaining LLMs with tools, retrievers, and external data sources.', 'You can customize the name of a given run when invoking or streaming your LangChain code by providing it in the Config . This name is used to identify the run in LangSmith and can be used to filter and group runs. The name is also used as the title of the run in the LangSmith UI.', 'First 10k base traces and extended upgrades per month for free Pay as you go thereafter: $0.50 per 1k base traces (14-day retention) Additional $4.50 per 1k extended traces (400-day retention) ... LangChain, LangGraph, and LangSmith help teams of all sizes, across all industries - from ambitious', 'Alternative LangSmith & LangGraph Platform deployment options, including hybrid and self-hosted so data doesn‚Äôt leave your VPC You will have 1 free seat with access to LangSmith (5k base traces/month included). You can purchase up to 10 seats with access to LangSmith (10k base traces/month included). You will be able to ship agents with our managed LangGraph Platform Cloud service, with 1 free dev-sized deployment included. Plus plans include 1 free dev-sized deployment. For my free Dev deployment for LangGraph Platform, is there a cap on the number of nodes executed? If you‚Äôre on the Plus plan, you get 1 free dev-sized deployment ‚Äì all usage in this deployment will be free no matter how many node executions are run.', 'Implement cost observability alongside model observability ‚Äîtrack token usage, trace volume, and evaluate latency . Use edge filtering or model -in-the-loop compression before uploading logs. LLM Observability : Challenges, Key Components & Best Practices .', 'Key Metrics : Hallucination Rate , Accuracy, Latency . Example : ‚ÄúDoes the model extract precise facts while avoiding hallucinated or out-of-context interpretations?‚Äù Balancing Trade-Offs Between Metrics . Sometimes, optimizing for one metric means compromising another.']}}\n",
      "{'generate': {'draft': 'Short answer\\n- LangChain is an open-source developer framework of composable building blocks for building LLM-powered applications (prompts, chains, agents, retrievers, memory, connectors). LangSmith is a complementary platform/SDK from the same ecosystem focused on observability, run-tracking, evaluation, labeling, and debugging of those applications. In short: LangChain = build; LangSmith = observe, test, and operate.\\n\\nFive‚Äëparagraph essay\\n\\n1) Introduction (motivation + thesis)\\nImagine you launch a customer‚Äësupport chatbot built with an LLM, then one day it starts ‚Äúhallucinating‚Äù and returning wrong facts after you switched models. Fixing that requires both the ability to change the agent‚Äôs architecture and the ability to inspect exactly what happened in a broken run. That split ‚Äî composing behavior vs. understanding and improving behavior in production ‚Äî is why the LangChain and LangSmith projects matter. Thesis: LangChain is a developer framework of composable building blocks for creating LLM-powered applications; LangSmith is a complementary observability/evaluation platform (and associated tooling) that helps you test, trace, debug, and monitor those applications ‚Äî so one is for building and the other is for operating and improving. This essay explains what each tool is, how they differ, and when to use one or both.\\n\\n2) What they are (background)\\nLangChain is an open-source library designed to make it easy to compose LLM calls with prompts, prompt templates, chains, agents (tool use and decision logic), memory, retrievers, and connectors to databases and vector stores. It aims to give engineers modular building blocks so they can prototype and ship complex LLM workflows quickly. LangSmith is a product (from the LangChain team) that provides LLM-native observability and evaluation: SDK + UI for run tracking, trace visualizations, labeled datasets, automated evaluators, comparison/A‚ÄìB testing, and tools for human‚Äëin‚Äëthe‚Äëloop labeling. They‚Äôre part of the same ecosystem and intentionally interoperate ‚Äî LangChain code can emit trace data that LangSmith ingests for analysis.\\n\\n3) Core purpose and positioning (how they complement each other)\\nLangChain‚Äôs focus is orchestration and composition: prompt management, sequence-of-steps (chains), tool invocation, retriever pipelines, output parsing, and integrations with model providers and storage backends. It‚Äôs where you define the cognitive architecture of your app. LangSmith‚Äôs focus is lifecycle management: it captures inputs/outputs and intermediate steps, surfaces traces and errors, provides metrics (latency, token usage, hallucination/accuracy rates), supports dataset labeling and evaluators, and helps you compare models or prompt variants. Positioning summary: LangChain = OSS library for development and prototyping; LangSmith = platform/SDK for production observability, debugging, and iterative improvement.\\n\\n4) Technical integration and practical considerations\\nIntegration is straightforward by design: you instrument LangChain chains (via callbacks/SDK hooks or run objects) so runs and intermediate steps are sent to LangSmith for storage and analysis. LangChain supports Python and JavaScript/TypeScript libraries plus a community of connectors; LangSmith exposes an SDK/API and a web UI for manual review and evaluation workflows. LangSmith stores run traces, model metadata, intermediate chain states, and runtime metrics ‚Äî useful for root-cause analysis but also something to treat carefully from a data‚Äëprivacy perspective. Practically, LangChain runs wherever your code runs (local, containers, serverless). LangSmith is typically provided as a hosted service with paid tiers and enterprise/self‚Äëhosted options (check current vendor docs for exact terms). Cost and compliance considerations matter: sending user messages or PII to a cloud observability service requires governance, redaction, or on‚Äëprem options if you have strict data residency needs.\\n\\n5) When to use which and conclusion\\nIf you‚Äôre building or prototyping an LLM application, start with LangChain ‚Äî it speeds up composing prompts, retrieval, tool use, and agent logic. If you‚Äôre shipping to production, or you need systematic debugging, model comparisons, dataset labeling, or metric-driven QA, add LangSmith (or an equivalent observability/eval system). For most production-grade LLM apps the recommended pattern is LangChain for building the behavior and LangSmith for capturing runs, surfacing regressions, and driving iterative improvements. They‚Äôre complementary: one lets you design what the model does; the other tells you whether it‚Äôs doing it correctly in the wild.\\n\\nNext steps ‚Äî what would you like me to do?\\n- I can convert your full outline into the longer 1,200‚Äì1,800 word article you sketched, with a two-column comparison table and a small dataflow diagram.\\n- Or I can produce the comparison table plus a short instrumentation code snippet (pseudo-code) that shows how to send LangChain runs to LangSmith.\\n- Or I can draft a tight decision checklist and rollout plan (pilot ‚Üí instrument ‚Üí expand) for adopting both in a team.\\n\\nWhich would you prefer?', 'revision_number': 2}}\n",
      "{'reflect': {'critique': 'Overall assessment (summary)\\n- Strong: Clear thesis and sensible organization ‚Äî the five-paragraph structure maps well to the assignment and communicates the core distinction: LangChain = build; LangSmith = observe/operate. The essay covers background, complementary positioning, technical integration, and practical considerations (privacy, cost), which are the right high-level topics.\\n- Improvements needed: more concrete examples, deeper technical specifics (how instrumentation works), evidence and citations, clearer audience framing, tighter prose in places, and better coverage of limitations/alternatives. With these changes the piece would be ready for publication as a 1,200‚Äì1,800 word explanatory article.\\n\\nDetailed critique and recommendations\\n\\n1) Introduction (motivation + thesis)\\n- What‚Äôs good: The customer-support hallucination scenario is a good, relatable hook. The thesis sentence is clear and sets reader expectations.\\n- Suggested edits:\\n  - Strengthen the opening hook with one concise, vivid sentence (e.g., ‚ÄúA sudden model swap broke a chatbot in production ‚Äî and no one could reproduce why.‚Äù) then follow with the scenario elaboration.\\n  - Make the thesis even more explicit about audience and purpose: who should read this? (engineers, product managers, SREs)\\n  - Target length: 120‚Äì200 words.\\n\\n2) Background / What they are\\n- What‚Äôs good: You list the main LangChain building blocks and LangSmith features succinctly.\\n- Add concrete examples:\\n  - Show a short real-world use case (e.g., a retrieval-augmented QA flow: prompt template -> retriever -> LLM -> output parser).\\n  - Give one or two concrete LangSmith features in action (e.g., trace visualization showing which tool an agent called before hallucinating; an automated evaluator comparing prompts A vs B).\\n- Technical detail to add: brief note on supported languages (Python / JS) and typical integration points (callbacks, run objects).\\n- Target length: 250‚Äì350 words.\\n\\n3) Core purpose and positioning\\n- What‚Äôs good: The distinction between composition/orchestration (LangChain) and lifecycle/observability (LangSmith) is clear.\\n- Add nuance:\\n  - Clarify that LangChain both runs locally and can be used in production deployments, while LangSmith is usually a centralized observability layer (hosted vs self-hosted tradeoffs).\\n  - Discuss where responsibilities overlap (e.g., LangChain emits traces; LangSmith ingests and stores them ‚Äî but some teams may build custom tracing on top of LangChain without LangSmith).\\n- Include a brief sentence on alternatives (e.g., Sentry/Datadog+custom instrumentation, W&B for experiments) so readers can weigh vendor lock-in.\\n- Target length: 200‚Äì300 words.\\n\\n4) Technical integration and practical considerations\\n- What‚Äôs good: You hit the main integration points and governance issues.\\n- Required concrete details:\\n  - Add a short pseudocode snippet (10‚Äì15 lines) showing how to attach a LangSmith callback/handler to a LangChain chain and emit a run trace. This makes your explanation actionable.\\n  - Specify what ‚Äútrace‚Äù contains: inputs, outputs, intermediate chain steps, tool calls, model metadata, timing, tokens consumed, and error contexts.\\n  - Give concrete privacy/compliance mitigations: client-side redaction, field-level hashing, storing PII off-trace, retention policies, or on-prem/self-host options.\\n  - Discuss cost drivers (token volume, number of runs, retention) and recommend estimation strategies.\\n- Target length: 300‚Äì450 words (include pseudocode and a callout on privacy/cost).\\n\\n5) When to use which and conclusion\\n- What‚Äôs good: Practical recommendation (start with LangChain; add LangSmith for production) is sensible.\\n- Expand with a short rollout checklist and concrete triggers that should prompt adopting observability:\\n  - Start a pilot when N users / M queries per day, or after first production regression.\\n  - Checklist: (1) instrument runs, (2) capture metadata and error contexts, (3) build evaluators, (4) set alerting and regression tests.\\n- Keep the conclusion crisp and action-oriented: one-line takeaway + next steps.\\n- Target length: 150‚Äì250 words.\\n\\nStyle, tone, and audience\\n- Decide audience and write to them: If readers are engineers, include code, dependency names, and APIs. If product or manager audience, focus more on process, risk, and cost.\\n- Tone: keep it technical but accessible ‚Äî prefer active voice, short paragraphs, and concrete examples over abstract statements.\\n- Language: avoid repeating ‚ÄúLangChain = build; LangSmith = observe‚Äù too often. Use synonyms (orchestration, composition; observability, evaluation, lifecycle) to keep rhythm.\\n\\nStructure and visuals\\n- For a longer article (1,200‚Äì1,800 words) include:\\n  - Two-column comparison table (LangChain vs LangSmith) ‚Äî you suggested this; do it. Columns: Purpose, Typical APIs, Data stored, Use cases, Hosted/self-hosted, Cost drivers, When to add.\\n  - Small dataflow diagram showing: client -> LangChain (chains/agents) -> model(s) -> LangSmith ingest (traces, labels) -> evaluator & alerting. If you want, I can draw an ASCII diagram or describe a simple graphic for a designer.\\n  - One pseudocode snippet for instrumentation.\\n- Visual aids will improve comprehension for non-technical stakeholders and make the article more actionable.\\n\\nEvidence, sources, and accuracy\\n- Add links/citations to official docs (LangChain, LangSmith), relevant blog posts, and any benchmark or case study you reference.\\n- If you make claims about metrics (e.g., ‚ÄúLangSmith reports hallucination rates‚Äù), explain how hallucination is measured or provide an example evaluation prompt and metric.\\n\\nLimitations and alternatives (add a short section)\\n- Cover tradeoffs: vendor lock-in, data residency, cost, learning curve for instrumentation, and edge cases (e.g., high-frequency workloads where trace volume is too large).\\n- Mention alternatives and complementary tooling: Sentry/Datadog for observability, W&B/MLflow for experiment tracking, OpenTelemetry for standard traces, and homegrown logging pipelines.\\n\\nRevision checklist (concrete next edits)\\n- Strengthen intro hook and declare audience (do this first).\\n- Expand background with a concrete RAG example and one LangSmith trace scenario.\\n- Insert a 10‚Äì15-line pseudocode snippet showing LangChain -> LangSmith instrumentation.\\n- Add a 2-column comparison table between LangChain and LangSmith.\\n- Add a short rollout checklist / pilot plan (3‚Äì6 bullet steps).\\n- Add 3‚Äì4 links to official docs or posts and one sentence about alternatives/limitations.\\n- Target final length: 1,200‚Äì1,800 words. If you prefer shorter, aim for ~700‚Äì900 words but keep code and the table; if you want to go deeper (case studies, benchmark data), expand to 2,000+ words.\\n\\nGrading (optional)\\n- Rough grade: B+ as submitted. Clear structure and correct high-level content but needs more actionable specifics, examples, citations, and attention to audience/voice to reach A-level.\\n\\nWhich next-step to choose (recommendation)\\n- If you want a ready-to-publish long article: choose the first option (1,200‚Äì1,800 word conversion with table and diagram).\\n- If you want to ship docs or start integration quickly: choose the second option (comparison table + instrumentation pseudocode).\\n- If you need an adoption plan for your org: choose the third option (decision checklist + rollout plan).\\nTell me which option you prefer and which audience (engineer / product / exec) to target, and I will produce the draft with the suggested code snippet, table, and diagram.'}}\n",
      "{'research_critique': {'content': ['In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangChain streamlines the development of conversational agents and tool-using AI. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', 'Compare LangChain, LangSmith, and Orq.ai to discover the best LLM development tools for building, deploying, and optimizing scalable AI applications. As a comprehensive platform for LLM product development, LangChain equips software teams with the tools needed to build, test, and deploy LLM-powered solutions at scale. While LangChain focuses on the flexibility and modularity required for building LLM-powered applications, LangSmith steps in to offer essential tools for deployment, monitoring, and optimization throughout the production process. Orq.ai offers several advantages over LangChain and LangSmith, providing a more integrated and efficient solution for LLM development. By offering an integrated solution that supports the entire LLM development lifecycle, Orq.ai enables teams to seamlessly build, deploy, and optimize LLM applications at scale, without needing to juggle multiple specialized tools.', \"ü¶úÔ∏èüîó LangChain ü¶úÔ∏èüîó LangChain LangChain is a framework that consists of a number of packages. ## langchain-core\\u200b The main `langchain` package contains chains and retrieval strategies that make up an application's cognitive architecture. `langchain` `langchain-openai`, `langchain-anthropic`, etc) so that they can be properly versioned and appropriately lightweight. `langchain-openai` `langchain-anthropic` ## langchain-community\\u200b This package contains third-party integrations that are maintained by the LangChain community. This contains integrations for various components (chat models, vector stores, tools, etc). `langgraph` is an extension of `langchain` aimed at building robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph. `langchain` A package to deploy LangChain chains as REST APIs. Makes it easy to get a production ready API up and running.\", 'LangChain is an open-source framework that gives developers the tools they need to create applications using large language models (LLMs). LangChain offers a number of tools and APIs that make it simple to link language models to external data sources, interact with their surroundings, and develop complicated applications. The primary use case for LangChain at the moment is chat-based apps on top of LLMs (particularly ChatGPT), also called ‚Äúchat interfaces.‚Äù In a recent interview, the company‚Äôs CEO Harrison Chase, said the ideal use case right now is a ‚Äúchat over your documents.‚Äù LangChain also provides additional features to improve the conversation experience for applications, such as streaming, which implies providing the output of the LLM token by token rather than all at once.', 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith # Get started with LangSmith **LangSmith** is a platform for building production-grade LLM applications. LangSmith + LangChain OSS For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph. LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith‚Äôs observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production. The LangSmith SDK and UI make building and running high-quality evaluations easy. - Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.', \"While LangChain helps you build workflows, LangSmith helps ensure that they run smoothly by offering tools for debugging, monitoring and managing complex AI systems. LangSmith operates by embedding itself into the LLM application stack, whether you're using LangChain or building custom pipelines to provide visibility, traceability and control at every stage of development and production. Factory, a company building AI agents to automate the Software Development Lifecycle (SDLC), uses LangSmith to help ensure secure, reliable LLM operations in enterprise environments. LangChain is well suited for designing and prototyping complex language model workflows, enabling seamless integration with external tools and APIs. Use LangSmith when you're ready to move into production and need robust tools for debugging, testing, monitoring and maintaining LLM applications at scale.\", 'LangChain is the open, composable framework that provides a standard interface for every model, tool, and database ‚Äì so you can build LLM apps that adapt as fast as the ecosystem evolves. How do I use LangChain with other products like LangSmith, LangGraph, or LangGraph Platform? LangChain provides a standard interface for connecting models, tools, and data, then integrates seamlessly with any of the Lang- family products. Use LangChain when you need fast integration and experimentation; use LangGraph when you need to build agents that can reliably handle complex tasks. Can I use LangChain in production? Should I start with LangChain or LangGraph for building agents? Use **LangChain** for **composability and model flexibility**‚Äî great for quickly chaining LLMs with tools, retrievers, and external data sources.', 'You can customize the name of a given run when invoking or streaming your LangChain code by providing it in the Config . This name is used to identify the run in LangSmith and can be used to filter and group runs. The name is also used as the title of the run in the LangSmith UI.', 'First 10k base traces and extended upgrades per month for free Pay as you go thereafter: $0.50 per 1k base traces (14-day retention) Additional $4.50 per 1k extended traces (400-day retention) ... LangChain, LangGraph, and LangSmith help teams of all sizes, across all industries - from ambitious', 'Alternative LangSmith & LangGraph Platform deployment options, including hybrid and self-hosted so data doesn‚Äôt leave your VPC You will have 1 free seat with access to LangSmith (5k base traces/month included). You can purchase up to 10 seats with access to LangSmith (10k base traces/month included). You will be able to ship agents with our managed LangGraph Platform Cloud service, with 1 free dev-sized deployment included. Plus plans include 1 free dev-sized deployment. For my free Dev deployment for LangGraph Platform, is there a cap on the number of nodes executed? If you‚Äôre on the Plus plan, you get 1 free dev-sized deployment ‚Äì all usage in this deployment will be free no matter how many node executions are run.', 'Implement cost observability alongside model observability ‚Äîtrack token usage, trace volume, and evaluate latency . Use edge filtering or model -in-the-loop compression before uploading logs. LLM Observability : Challenges, Key Components & Best Practices .', 'Key Metrics : Hallucination Rate , Accuracy, Latency . Example : ‚ÄúDoes the model extract precise facts while avoiding hallucinated or out-of-context interpretations?‚Äù Balancing Trade-Offs Between Metrics . Sometimes, optimizing for one metric means compromising another.', '–¶–µ–ø–æ—á–∫–∏ –≤—ã–∑–æ–≤–æ–≤ ( Chains ). –§—Ä–µ–π–º–≤–æ—Ä–∫ –≤–≤–æ–¥–∏—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏—é Chain ‚Äì –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —à–∞–≥–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –≤–∫–ª—é—á–∞—Ç—å –≤—ã–∑–æ–≤—ã –º–æ–¥–µ–ª–µ–π –∏ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π Python -–∫–æ–¥. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–µ–∫–ª–∞—Ä–∞—Ç–∏–≤–Ω–æ –æ–ø–∏—Å—ã–≤–∞—Ç—å –ø–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö. LangChain –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–µ —Ü–µ–ø–æ—á–∫–∏', '| Connery | No | Yes | Commercial | API actions | https://python.langchain.com/docs/integrations/tools/connery | | Dall-E Image Generator | No | Yes | Proprietary | Text-to-image generation | https://python.langchain.com/docs/integrations/tools/dalle_image_generator | | DuckDuckGo Search | No | No | Open source | Privacy-focused search | https://python.langchain.com/docs/integrations/tools/ddg | | Google Scholar | Yes | Yes | Proprietary | Scholarly article search | https://python.langchain.com/docs/integrations/tools/google_scholar | | HuggingFace Hub | No | No | Open source | Hugging Face models, datasets | https://python.langchain.com/docs/integrations/tools/huggingface_tools | | SerpAPI | No | Yes | Commercial | Search engine results page scraping | https://python.langchain.com/docs/integrations/tools/serpapi | | Wikidata | No | No | Open source | Structured data access | https://python.langchain.com/docs/integrations/tools/wikidata | | Wikipedia | No | No | Open source | Wikipedia access | https://python.langchain.com/docs/integrations/tools/wikipedia |', 'This conceptual guide covers topics related to managing users, organizations, and workspaces within LangSmith. Users may have permissions in a workspace that grant them access to the resources in that workspace, including tracing projects, datasets, annotation queues, and prompts. | Data Retention, Usage Limits | Workspace | Data retention settings and usage limits will be available soon for the organization level as well *Self-hosted installations may enable workspace-level invites of users to the organization via a feature flag. Organization Admin grants full access to manage all organization configuration, users, billing, and workspaces. In organizations limited to a single workspace, all users are Organization Admins. LangSmith Traces (Extended Data Retention Upgrades). Extended data retention traces limit', 'LangSmith Performance cookies are used to understand and analyze the key performance indexes of the website which helps in delivering a better user experience for the visitors. LangSmith is a unified observability & evals platform where teams can debug, test, and monitor AI app performance ‚Äî whether building with LangChain or not. Evaluate your app by saving production traces to datasets ‚Äî then score performance with LLM-as-Judge evaluators. LangSmith traces contain the full information of all the inputs and outputs of each step of the application, giving users full visibility into their agent or LLM app behavior. LangSmith also allows users to instantly run evals to assess agent or LLM app performance ‚Äî including LLM-as-Judge evaluators for auto-scoring and the ability to attach human feedback.', 'Platform architecture and best practices .They started with a basic gateway for audit trails, evolved to include PII redaction , self - hosted models, and RAG capabilities, while focusing on user adoption and security.', 'Deploying LLM applications into production is complex. This guide explains LLM observability - why it matters, common failure modes like hallucinations, key tool features, and how to get started with W&B Weave.']}}\n",
      "{'generate': {'draft': 'Imagine you ship a customer-support chatbot built with a new model and then users start reporting confidently wrong answers (hallucinations). You need two things: fast, flexible tools to build and iterate the agent, and robust observability to trace, debug, and measure regressions. LangChain and LangSmith aim at those two halves of the problem. Thesis: LangChain is a developer framework of composable building blocks for creating LLM-powered applications; LangSmith is a complementary observability and evaluation platform (and associated tooling) that helps you test, trace, debug, and monitor those applications ‚Äî so one is for building and the other is for operating and improving. This essay explains what each product is, how they differ, and pragmatic guidance on when to use either or both.\\n\\nAt a high level: LangChain is an open-source library for composing LLM functionality into applications. It provides prompt templates, chains (pipelines of steps), agents (tool-using LLMs), memory, retrievers and vectorstore connectors, output parsers, and many community integrations across Python and JavaScript/TypeScript. Its purpose is orchestration and composability: glue LLMs to data, tools, and business logic so you can prototype and ship complex behaviors. LangSmith, developed by the same ecosystem, is a platform (typically SaaS with SDKs) focused on observability, evaluation, and lifecycle management. LangSmith captures run traces (inputs, outputs, intermediate steps, metadata), provides a web UI for debugging and visualizing chains, supports human-in-the-loop labeling and automated evaluators, and helps compare models and A/B tests. They are designed to interoperate: instrumented LangChain runs can be reported to LangSmith for analysis.\\n\\nThe core difference is therefore purpose and placement in the workflow. LangChain = build. It exposes primitives to design flows: prompt engineering, chaining LLM calls, hooking external tools (search, databases, APIs), and managing state across turns. LangSmith = run and improve. It captures rich telemetry (full traces, per-step outputs, latencies, model and token usage), surfaces failure modes (where a chain produced unexpected output), stores labeled datasets for evals, and offers evaluators (including LLM-as-judge) to score and compare model behavior over time. In practice a typical workflow is: implement your agent with LangChain primitives ‚Üí add lightweight instrumentation or callbacks ‚Üí stream runs to LangSmith ‚Üí use the UI and automated evals to find regressions, tune prompts, or choose the better model. LangChain stays in your codebase and remains portable; LangSmith adds operational tooling and often a managed service that stores your traces and evaluation artifacts.\\n\\nPractical considerations that affect the choice: cost, deployment, and data governance. LangChain is open-source and runs wherever your code runs (serverless, containers, VMs); your primary costs are model API calls, vector store hosting, and infra. LangSmith generally offers a free tier and paid plans (and some enterprise/self-hosting options depending on the vendor), because it‚Äôs a managed telemetry/eval platform; that implies per-trace storage and retention pricing and potential data residency questions. If your app handles PII or regulated data, confirm redaction and retention features (sample first, use local logging/export strategies to avoid lock-in). Operationally, use LangChain alone for fast prototyping or research. Use LangSmith when you need repeatable evaluations, traceable debugging, or to scale quality assurance across teams. Quick decision checklist: \\n- Prototyping/research only? Start with LangChain. \\n- Need per-step traces, evals, or labeling for production quality? Add LangSmith. \\n- Concerned about vendor lock-in or data residency? Pilot with sampling and verify export/retention features.\\n\\nIn short: LangChain and LangSmith are complementary. LangChain gives you the flexible, composable building blocks to create LLM apps; LangSmith gives you the observability, evaluation, and operational tooling to run those apps reliably at scale. For production-grade LLM systems you‚Äôll commonly use both: LangChain to build and iterate on behavior, and LangSmith to measure, debug, and certify that behavior over time. Verify current product details (pricing, export, and self-host options) from the official docs before adopting at scale.', 'revision_number': 3}}\n",
      "{'reflect': {'critique': 'Overall impression\\n- Strong, clear thesis: you distinguish build (LangChain) vs operate/observe (LangSmith) and explain how they interoperate.\\n- Concise and practically useful: the essay gives readers an actionable decision checklist and calls out cost/privacy tradeoffs.\\n- Well organized: high-level description ‚Üí core difference ‚Üí workflow ‚Üí practical considerations ‚Üí quick checklist ‚Üí conclusion.\\n\\nGrade: B+ (Good conceptual clarity and usefulness, but missing concrete evidence, implementation detail, and supporting examples that would make it production-ready guidance.)\\n\\nMajor strengths\\n1. Clarity of purpose: The central distinction (LangChain = building/orchestration; LangSmith = observability/eval) is stated crisply and repeated helpfully.\\n2. Practical orientation: The decision checklist and the notes about cost, deployment, and data governance are exactly the kinds of things practitioners want.\\n3. Balanced tone: You avoid overselling and include an appropriate note to verify current product details.\\n\\nAreas for improvement (high priority)\\n1. Add concrete examples and case studies\\n   - Show a short realistic scenario where hallucinations occur (example query, expected answer, hallucinated answer).\\n   - Walk through how instrumented LangChain execution is sent to LangSmith and what a trace would show (e.g., intermediate tool calls, prompt versions, per-step outputs).\\n   - Include one or two mini-case studies: e.g., ‚ÄúSearch+RAG agent that hallucinated due to stale store‚Äù or ‚Äútool misuse causing confident wrong answers‚Äù and show how observability found root cause.\\n2. Provide empirical/operational guidance and metrics\\n   - Define measurable metrics to track (hallucination rate, accuracy, precision/recall on QA, latency per step, tokens/cost per session, model drift).\\n   - Describe thresholds and alerting strategy (e.g., >3% hallucination triggers investigation, or model A/B test significance).\\n   - Explain evaluation methodology (holdout sets, LLM-as-judge caveats, human labeling workflows, inter-annotator agreement).\\n3. Add implementation-level details\\n   - Include sample code snippets (Python/JS) showing how to add LangSmith callbacks or telemetry to LangChain runs, or a minimal snippet illustrating a chain with tracing enabled.\\n   - Show a sample trace or a JSON schema of captured metadata (inputs, tool calls, outputs, timestamps, model id, prompt version).\\n4. Evidence and citations\\n   - Link to official docs for LangChain and LangSmith, pricing pages, and privacy/retention docs. Cite sources for claims about data residency or self-hosting options.\\n   - If you assert a specific feature (e.g., LLM-as-judge in LangSmith), either show a screenshot/trace example, or cite the docs to avoid misstatements.\\n5. Discuss limitations and risks\\n   - Add a short section on when LangSmith might not be necessary, potential vendor lock-in, data-exfiltration risks, and mitigation strategies (sampling, redaction, local logging).\\n   - Mention failure modes of automated evaluators (bias in LLM judges, sensitivity to phrasing) and the need for human-in-the-loop validation.\\n\\nAreas for improvement (medium priority)\\n1. Structure and depth\\n   - Expand the essay to include subheadings and clearer sectioning for readers scanning for how-to steps, cost, architecture, and legal considerations.\\n   - Depth: provide concrete recommended workflows for prototyping (quick start) vs production (CI/CD for prompts and models).\\n2. Audience and voice\\n   - Clarify the target audience up front (e.g., engineers integrating LLMs into products, ML engineers, PMs evaluating observability tooling). Tailor examples and code to that audience.\\n   - Reduce marketing-sounding phrases; prefer neutral, evidence-based language in a technical essay.\\n3. Style and readability\\n   - Add one or two diagrams (sequence diagram or dataflow) and a sample checklist box for onboarding the team.\\n   - Break long paragraphs; use bullet lists for metrics, steps, or tradeoffs.\\n\\nConcrete revisions I recommend (prioritized checklist)\\n1. Add a 300‚Äì600 word runnable example (code + sample trace) showing: chain + LangSmith instrumentation ‚Üí trace capture ‚Üí root-cause discovery.\\n2. Add an ‚ÄúEvaluation & Metrics‚Äù section (400‚Äì800 words) that:\\n   - Defines 6‚Äì8 metrics (hallucination rate, answer accuracy, latency, cost per session, % human-labels, model A/B p-value).\\n   - Describes how to compute them and recommended alert thresholds.\\n3. Add a ‚ÄúSecurity & Data Governance‚Äù paragraph (200‚Äì400 words) with concrete options: sampling, redaction, local export, self-hosting, SLA considerations.\\n4. Add citations/links to official LangChain and LangSmith docs and pricing pages; if unsure, mark as ‚Äúcheck link before publishing.‚Äù\\n5. Insert a short (150‚Äì300 words) case study summarizing a hypothetical production incident and the SLA/operational lessons learned.\\n6. Include a short ‚ÄúHow to instrument‚Äù appendix: 8‚Äì12 line Python and JS code showing how to activate LangSmith tracing/callbacks in LangChain.\\n7. Suggested final length:\\n   - Blog post: 900‚Äì1,400 words with a code example and one case study.\\n   - Engineer-facing guide / whitepaper: 1,800‚Äì3,000 words including metrics, diagrams, code, and citations.\\n   - One-page executive summary: 300‚Äì450 words with the decision checklist and cost/residency bullets.\\n\\nStylistic suggestions\\n- Use active voice and consistent verb tense.\\n- Replace ambiguous phrases (‚Äúdeveloped by the same ecosystem‚Äù) with precise terms or note ‚Äúverify authorship.‚Äù\\n- Keep the decision checklist as a visually distinct block when publishing (readers like checklists).\\n- When introducing acronyms (RAG, PII), define them on first use.\\n\\nOptional advanced content (if you want to make it authoritative)\\n- Include a short A/B testing plan for models (sample size estimation, metrics to compare, significance testing).\\n- Add a suggested CI workflow: automated test suite with representative prompts, nightly evals logged to LangSmith, alerts for regression, gating for deployment.\\n- Discuss pros/cons vs alternatives (open-source observability stacks, homegrown logging, full self-hosted pipelines).\\n\\nWhat I want to see in your revision\\n- A concrete example trace (realistic, sanitized) showing how observability helped fix hallucination.\\n- One or more citations/links to official docs or blog posts.\\n- Clearer, actionable metrics and suggested thresholds or processes for escalation.\\n\\nIf you send a revision, include the intended audience and target format (blog post vs engineer guide vs whitepaper) so I can tailor the feedback to that audience and expected length.'}}\n",
      "{'research_critique': {'content': ['In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangChain streamlines the development of conversational agents and tool-using AI. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', 'Compare LangChain, LangSmith, and Orq.ai to discover the best LLM development tools for building, deploying, and optimizing scalable AI applications. As a comprehensive platform for LLM product development, LangChain equips software teams with the tools needed to build, test, and deploy LLM-powered solutions at scale. While LangChain focuses on the flexibility and modularity required for building LLM-powered applications, LangSmith steps in to offer essential tools for deployment, monitoring, and optimization throughout the production process. Orq.ai offers several advantages over LangChain and LangSmith, providing a more integrated and efficient solution for LLM development. By offering an integrated solution that supports the entire LLM development lifecycle, Orq.ai enables teams to seamlessly build, deploy, and optimize LLM applications at scale, without needing to juggle multiple specialized tools.', \"ü¶úÔ∏èüîó LangChain ü¶úÔ∏èüîó LangChain LangChain is a framework that consists of a number of packages. ## langchain-core\\u200b The main `langchain` package contains chains and retrieval strategies that make up an application's cognitive architecture. `langchain` `langchain-openai`, `langchain-anthropic`, etc) so that they can be properly versioned and appropriately lightweight. `langchain-openai` `langchain-anthropic` ## langchain-community\\u200b This package contains third-party integrations that are maintained by the LangChain community. This contains integrations for various components (chat models, vector stores, tools, etc). `langgraph` is an extension of `langchain` aimed at building robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph. `langchain` A package to deploy LangChain chains as REST APIs. Makes it easy to get a production ready API up and running.\", 'LangChain is an open-source framework that gives developers the tools they need to create applications using large language models (LLMs). LangChain offers a number of tools and APIs that make it simple to link language models to external data sources, interact with their surroundings, and develop complicated applications. The primary use case for LangChain at the moment is chat-based apps on top of LLMs (particularly ChatGPT), also called ‚Äúchat interfaces.‚Äù In a recent interview, the company‚Äôs CEO Harrison Chase, said the ideal use case right now is a ‚Äúchat over your documents.‚Äù LangChain also provides additional features to improve the conversation experience for applications, such as streaming, which implies providing the output of the LLM token by token rather than all at once.', 'Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith # Get started with LangSmith **LangSmith** is a platform for building production-grade LLM applications. LangSmith + LangChain OSS For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph. LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith‚Äôs observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production. The LangSmith SDK and UI make building and running high-quality evaluations easy. - Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.', \"While LangChain helps you build workflows, LangSmith helps ensure that they run smoothly by offering tools for debugging, monitoring and managing complex AI systems. LangSmith operates by embedding itself into the LLM application stack, whether you're using LangChain or building custom pipelines to provide visibility, traceability and control at every stage of development and production. Factory, a company building AI agents to automate the Software Development Lifecycle (SDLC), uses LangSmith to help ensure secure, reliable LLM operations in enterprise environments. LangChain is well suited for designing and prototyping complex language model workflows, enabling seamless integration with external tools and APIs. Use LangSmith when you're ready to move into production and need robust tools for debugging, testing, monitoring and maintaining LLM applications at scale.\", 'LangChain is the open, composable framework that provides a standard interface for every model, tool, and database ‚Äì so you can build LLM apps that adapt as fast as the ecosystem evolves. How do I use LangChain with other products like LangSmith, LangGraph, or LangGraph Platform? LangChain provides a standard interface for connecting models, tools, and data, then integrates seamlessly with any of the Lang- family products. Use LangChain when you need fast integration and experimentation; use LangGraph when you need to build agents that can reliably handle complex tasks. Can I use LangChain in production? Should I start with LangChain or LangGraph for building agents? Use **LangChain** for **composability and model flexibility**‚Äî great for quickly chaining LLMs with tools, retrievers, and external data sources.', 'You can customize the name of a given run when invoking or streaming your LangChain code by providing it in the Config . This name is used to identify the run in LangSmith and can be used to filter and group runs. The name is also used as the title of the run in the LangSmith UI.', 'First 10k base traces and extended upgrades per month for free Pay as you go thereafter: $0.50 per 1k base traces (14-day retention) Additional $4.50 per 1k extended traces (400-day retention) ... LangChain, LangGraph, and LangSmith help teams of all sizes, across all industries - from ambitious', 'Alternative LangSmith & LangGraph Platform deployment options, including hybrid and self-hosted so data doesn‚Äôt leave your VPC You will have 1 free seat with access to LangSmith (5k base traces/month included). You can purchase up to 10 seats with access to LangSmith (10k base traces/month included). You will be able to ship agents with our managed LangGraph Platform Cloud service, with 1 free dev-sized deployment included. Plus plans include 1 free dev-sized deployment. For my free Dev deployment for LangGraph Platform, is there a cap on the number of nodes executed? If you‚Äôre on the Plus plan, you get 1 free dev-sized deployment ‚Äì all usage in this deployment will be free no matter how many node executions are run.', 'Implement cost observability alongside model observability ‚Äîtrack token usage, trace volume, and evaluate latency . Use edge filtering or model -in-the-loop compression before uploading logs. LLM Observability : Challenges, Key Components & Best Practices .', 'Key Metrics : Hallucination Rate , Accuracy, Latency . Example : ‚ÄúDoes the model extract precise facts while avoiding hallucinated or out-of-context interpretations?‚Äù Balancing Trade-Offs Between Metrics . Sometimes, optimizing for one metric means compromising another.', '–¶–µ–ø–æ—á–∫–∏ –≤—ã–∑–æ–≤–æ–≤ ( Chains ). –§—Ä–µ–π–º–≤–æ—Ä–∫ –≤–≤–æ–¥–∏—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏—é Chain ‚Äì –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —à–∞–≥–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –≤–∫–ª—é—á–∞—Ç—å –≤—ã–∑–æ–≤—ã –º–æ–¥–µ–ª–µ–π –∏ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π Python -–∫–æ–¥. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–µ–∫–ª–∞—Ä–∞—Ç–∏–≤–Ω–æ –æ–ø–∏—Å—ã–≤–∞—Ç—å –ø–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö. LangChain –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–µ —Ü–µ–ø–æ—á–∫–∏', '| Connery | No | Yes | Commercial | API actions | https://python.langchain.com/docs/integrations/tools/connery | | Dall-E Image Generator | No | Yes | Proprietary | Text-to-image generation | https://python.langchain.com/docs/integrations/tools/dalle_image_generator | | DuckDuckGo Search | No | No | Open source | Privacy-focused search | https://python.langchain.com/docs/integrations/tools/ddg | | Google Scholar | Yes | Yes | Proprietary | Scholarly article search | https://python.langchain.com/docs/integrations/tools/google_scholar | | HuggingFace Hub | No | No | Open source | Hugging Face models, datasets | https://python.langchain.com/docs/integrations/tools/huggingface_tools | | SerpAPI | No | Yes | Commercial | Search engine results page scraping | https://python.langchain.com/docs/integrations/tools/serpapi | | Wikidata | No | No | Open source | Structured data access | https://python.langchain.com/docs/integrations/tools/wikidata | | Wikipedia | No | No | Open source | Wikipedia access | https://python.langchain.com/docs/integrations/tools/wikipedia |', 'This conceptual guide covers topics related to managing users, organizations, and workspaces within LangSmith. Users may have permissions in a workspace that grant them access to the resources in that workspace, including tracing projects, datasets, annotation queues, and prompts. | Data Retention, Usage Limits | Workspace | Data retention settings and usage limits will be available soon for the organization level as well *Self-hosted installations may enable workspace-level invites of users to the organization via a feature flag. Organization Admin grants full access to manage all organization configuration, users, billing, and workspaces. In organizations limited to a single workspace, all users are Organization Admins. LangSmith Traces (Extended Data Retention Upgrades). Extended data retention traces limit', 'LangSmith Performance cookies are used to understand and analyze the key performance indexes of the website which helps in delivering a better user experience for the visitors. LangSmith is a unified observability & evals platform where teams can debug, test, and monitor AI app performance ‚Äî whether building with LangChain or not. Evaluate your app by saving production traces to datasets ‚Äî then score performance with LLM-as-Judge evaluators. LangSmith traces contain the full information of all the inputs and outputs of each step of the application, giving users full visibility into their agent or LLM app behavior. LangSmith also allows users to instantly run evals to assess agent or LLM app performance ‚Äî including LLM-as-Judge evaluators for auto-scoring and the ability to attach human feedback.', 'Platform architecture and best practices .They started with a basic gateway for audit trails, evolved to include PII redaction , self - hosted models, and RAG capabilities, while focusing on user adoption and security.', 'Deploying LLM applications into production is complex. This guide explains LLM observability - why it matters, common failure modes like hallucinations, key tool features, and how to get started with W&B Weave.', 'Trace with LangChain (Python and JS/TS) | ü¶úÔ∏èüõ†Ô∏è LangSmith from langchain_core.tracers.context import tracing_v2_enabled   from langchain_core.tracers.context import tracing_v2_enabled   from langchain_core.tracers.context import tracing_v2_enabled   LangSmith supports distributed tracing with LangChain Python. LangChain objects will be traced when invoked within a `traceable` function and be bound as a child run of the `traceable` function. Starting with `langchain@0.2.x`, LangChain objects are traced automatically when used inside `@traceable` functions, inheriting the client, tags, metadata and project name of the traceable function. ### Tracing LangChain child runs via `traceable` / RunTree API (JS only)\\u200b In some uses cases, you might want to run `traceable` functions as part of the RunnableSequence or trace child runs of LangChain run imperatively via the `RunTree` API. - Tracing LangChain child runs via `traceable` / RunTree API (JS only)', 'LangSmith Performance cookies are used to understand and analyze the key performance indexes of the website which helps in delivering a better user experience for the visitors. LangSmith is a unified observability & evals platform where teams can debug, test, and monitor AI app performance ‚Äî whether building with LangChain or not. Evaluate your app by saving production traces to datasets ‚Äî then score performance with LLM-as-Judge evaluators. LangSmith traces contain the full information of all the inputs and outputs of each step of the application, giving users full visibility into their agent or LLM app behavior. LangSmith also allows users to instantly run evals to assess agent or LLM app performance ‚Äî including LLM-as-Judge evaluators for auto-scoring and the ability to attach human feedback.', 'Alternative LangSmith & LangGraph Platform deployment options, including hybrid and self-hosted so data doesn‚Äôt leave your VPC You will have 1 free seat with access to LangSmith (5k base traces/month included). You can purchase up to 10 seats with access to LangSmith (10k base traces/month included). You will be able to ship agents with our managed LangGraph Platform Cloud service, with 1 free dev-sized deployment included. Plus plans include 1 free dev-sized deployment. For my free Dev deployment for LangGraph Platform, is there a cap on the number of nodes executed? If you‚Äôre on the Plus plan, you get 1 free dev-sized deployment ‚Äì all usage in this deployment will be free no matter how many node executions are run.', 'LangSmith for Startups offers discounted prices and a generous free, monthly trace allotment, so you can have the right tooling in place as you grow your business. First 5k base traces and extended upgrades per month for free First 10k base traces and extended upgrades per month for free For teams that want to self-serve LangSmith, check out the Plus plan. If you‚Äôve consumed the monthly allotment of free traces in your account, you can purchase credits via credit card on the Developer and Plus plans to continue sending traces to LangSmith. On the Enterprise plan, you‚Äôll get white-glove support with a Slack channel, a dedicated customer success engineer, and monthly check-ins to go over LangSmith and LangChain questions.', 'Missing: case study troubleshooting sample trace root cause example 08/08/2025']}}\n",
      "{'generate': {'draft': 'Introduction\\nA helpful way to see the difference between LangChain and LangSmith is a simple failure mode: your customer-support bot suddenly starts hallucinating facts after you swap models ‚Äî users complain, metrics dip, and you don‚Äôt know whether the issue is prompt drift, a retriever problem, or a model regression. That gap ‚Äî between building LLM workflows and reliably operating them in production ‚Äî is precisely what differentiates the two offerings. Thesis: LangChain is a developer framework of composable building blocks for creating LLM-powered applications; LangSmith is a complementary observability/evaluation platform (and associated tooling) that helps you test, trace, debug, and monitor those applications ‚Äî so one is for building and the other is for operating and improving. This essay explains what each product is, how they work together, practical trade-offs, and when to choose one or both.\\n\\nBackground / Definitions\\nLangChain is an open-source, language-agnostic framework (popular Python and JavaScript/TypeScript SDKs) focused on composing language-model-based workflows. It provides primitives‚Äîprompt templates, chains (call sequences), agents (tool-using workflows), memory, retrievers, vector stores, connectors to data sources, output parsers, and callbacks‚Äîso developers can assemble complex LLM apps (RAG, chatbots, multi-step agents) without reinventing orchestration logic. LangSmith is a tooling platform built by the LangChain team to fill the operational gap: it captures run-level telemetry, visualizes step-by-step traces, supports dataset labeling and automated evaluations, and provides a UI/SDK for run management, model comparison, and debugging. Because both come from the same ecosystem they are designed to interoperate easily, but their goals differ: LangChain to build; LangSmith to observe, evaluate, and iterate.\\n\\nCore purpose and technical comparison\\nAt a conceptual level LangChain and LangSmith occupy adjacent but distinct layers:\\n- LangChain (build layer): provides the code-level primitives and integrations to orchestrate LLM calls, attach tools (search, APIs), and handle state. It emphasizes composability, modularity, and extensibility so teams can prototype and ship novel LLM logic quickly.\\n- LangSmith (operate layer): captures and stores runs from LLM apps (inputs, outputs, intermediate steps, model metadata, timing), displays nested traces, enables automated and human-in-the-loop evaluations (including LLM-as-judge scoring), manages labeled datasets for evals, and helps compare models/A‚ÄìB test prompts.\\n\\nIntegration and workflow are straightforward: instrument LangChain chains (via callbacks/tracers or explicit SDK calls) ‚Üí send runs/metadata to LangSmith ‚Üí inspect traces in the UI, run evaluators, label failures, and iterate on prompts/models/retrievers. LangChain‚Äôs extensible integrations let you plug in many model providers and vector stores; LangSmith accepts those runs and augments them with observability, retention, and evaluation tools. Key technical items to note: LangSmith stores intermediate steps (helpful for diagnosing agent/tool failures), model usage/latency metrics, and supports export/retention controls (verify latest policies). Always check current docs for SDK apis and host/self-host options before productionizing.\\n\\nQuick comparison (one-line)\\n- Goal: LangChain = compose LLM logic; LangSmith = trace and evaluate LLM behavior.\\n- Primary users: LangChain = developers/engineers; LangSmith = engineers/QA/MLOps/product teams.\\n- Product type: LangChain = open-source SDK; LangSmith = observability/evals platform (SaaS + enterprise options).\\n- Workflow stage: LangChain = design/prototype/implement; LangSmith = test/monitor/iterate in staging/production.\\n\\nPractical considerations, costs, and example use cases\\nLicensing and cost: LangChain is open-source (no license fee) but you still pay for model API calls, hosting, vector DBs, etc. LangSmith is a hosted observability/evaluation service with free trace allotments and paid tiers for higher retention and seats‚Äîconfirm current pricing and free-tier limits on the vendor site. Deployment and security: LangChain code runs wherever you deploy it (serverless, containers, VMs). LangSmith typically operates as a SaaS product with enterprise and hybrid/self-host options in some plans‚Äîevaluate data residency, PII redaction, and exportability if compliance is a concern. Vendor lock-in: you can reduce it by exporting traces and keeping local logs; LangChain code remains portable across environments and providers.\\n\\nWhen to use what\\n- LangChain only: fast prototyping, research, or tiny apps where ad-hoc logs and basic metrics suffice.\\n- LangSmith only (rare): teams who already have custom LLM orchestration but need a third-party eval/observability layer.\\n- LangChain + LangSmith (recommended for production): build with LangChain and instrument runs so LangSmith can surface hallucination rates, latency regressions, retriever failures, and support A/B comparisons of prompts or models. Example trace instrumentation (high-level pseudo-code):\\n  - Create a LangChain chain or agent\\n  - Wrap it with a traceable function or add a callback to emit runs to LangSmith\\n  - Run in staging, inspect traces, label errors, run automated evaluators, then iterate\\nStart with sampling (send a fraction of runs) to limit cost, then broaden coverage once your eval suite is stable.\\n\\nConclusion\\nIn short: LangChain is the composable toolkit that helps you build LLM applications; LangSmith is the observability and evaluation layer that helps you run those applications reliably and improve them over time. For engineers and product teams building production-grade LLM products, the sensible baseline is to use LangChain for development and add LangSmith (or an equivalent observability/eval platform) as you move to staging and production. If you‚Äôd like, I can expand this into the full article from your outline (with the 1,200‚Äì1,800 word target), produce the two-column comparison table, and include a short runnable instrumentation snippet‚Äîwhich would you prefer?', 'revision_number': 4}}\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for s in graph.stream({\n",
    "    'task': \"what is the difference between langchain and langsmith\",\n",
    "    \"max_revisions\": 3,\n",
    "    \"revision_number\": 0,\n",
    "    \"content\": [],\n",
    "}, thread):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad8a6cc-65d4-4ce7-87aa-4e67d7c23d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d1664b5-75e0-46b7-9c2b-4ac9171f4597",
   "metadata": {},
   "source": [
    "## Essay Writer Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ae270-3ec3-484a-b729-df7d2b7b0f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from helper import ewriter, writer_gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ebfa79-c7fc-4aaa-b668-64e5b6cede80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiAgent = ewriter()\n",
    "# app = writer_gui(MultiAgent.graph)\n",
    "# app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b5e62-a203-433c-92a0-3783f490cde1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa923c-7e4f-42d1-965f-0f8ccd50fbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c6245-2837-4ac5-983b-95f61f3ac10d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b910915-b087-4d35-afff-0ec30a5852f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4feb6cc-5129-4a99-bb45-851bc07b5709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a02b4-96cc-4b01-8792-397a774eb499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8b86a6-5e20-4252-b1d8-009b8318345a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af925917-b746-48c9-ac74-62fefbe5246c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5048f2c-4d82-49a5-9cb1-918d78b39f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f7f1f-68b4-4462-bfa5-b6472ef1304a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac0aa9-baa7-4b58-889d-2118cc00c6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6098b9-e2a9-4767-8cb5-346db835c8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d23cf2a-a179-44dc-9ae3-2eddda4b67b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6005b-0221-4f5e-9be0-0580c1d03126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1ec12-f1c8-41ae-bb3e-5f28997b9b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c07d7-be17-4c17-82c5-6fe1db028b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04592c8e-1cfe-4b26-93b5-caf1ed1e7d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181c4a9-0e71-4f67-b71f-18a225e37202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c478a9-7bfe-49e2-8a7d-1536271f45a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d6771-3fad-4f37-9b32-45b36ad85c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3629eb3-655d-467a-b413-63f547c2de08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f772f251-2b61-4d10-97c5-61cef9207a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de92979-7ac5-4a7c-91c1-10806b7d529c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c4325-f625-4bbf-9d74-cc58f10763f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4070be7-72da-42f9-a25d-8a6c628788b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289efbe-7033-4f32-8482-2039c5f9db90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e480bb-22ab-4acb-a42c-71da3d04a5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dea35c-7483-4b3d-b5e3-76eb3a0fe536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac5730-a9d5-4ea4-8546-ebcb265cf1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e1f28b-46d8-4bcd-b2e4-730376ee7ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ac7020-b4f4-4bd2-a875-ccee93f83d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f79eb9-d1c9-44b0-9efd-a8f9b380332a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce509206-bde1-43e4-a88f-8a565539d357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba1590-9e7b-4c0f-9492-81a07d286c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8fe4a8-5372-479d-b248-af7a295c86c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7514720a-14bc-4552-ade5-fa03f86f4c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
