{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6df9db6",
   "metadata": {},
   "source": [
    "## Checkpoint/Snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df48314b",
   "metadata": {},
   "source": [
    "Checkpoint to store graph state. It manages the checkpoints by threads (in the chat). That's why when run graph, you need to provide a config that contain `thread_id`\n",
    "\n",
    "``config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph.invoke({\"foo\": \"\"}, config)``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3985d0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'foo': 'b', 'bar': ['a', 'b']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from operator import add\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: str\n",
    "    bar: Annotated[list[str], add]\n",
    "\n",
    "def node_a(state: State):\n",
    "    return {\"foo\": \"a\", \"bar\": [\"a\"]}\n",
    "\n",
    "def node_b(state: State):\n",
    "    return {\"foo\": \"b\", \"bar\": [\"b\"]}\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(node_a)\n",
    "workflow.add_node(node_b)\n",
    "workflow.add_edge(START, \"node_a\")\n",
    "workflow.add_edge(\"node_a\", \"node_b\")\n",
    "workflow.add_edge(\"node_b\", END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph.invoke({\"foo\": \"\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c0fdfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSnapshot(values={'foo': 'b', 'bar': ['a', 'b']}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f7a-6815-8002-69d9a10b72c8'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-08-07T06:06:04.607694+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f75-69e8-8001-cce7a15196a1'}}, tasks=(), interrupts=())\n"
     ]
    }
   ],
   "source": [
    "print(graph.get_state(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87438231",
   "metadata": {},
   "source": [
    "### Get state history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02974710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'foo': 'b', 'bar': ['a', 'b']}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f7a-6815-8002-69d9a10b72c8'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-08-07T06:06:04.607694+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f75-69e8-8001-cce7a15196a1'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'foo': 'a', 'bar': ['a']}, next=('node_b',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f75-69e8-8001-cce7a15196a1'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-08-07T06:06:04.605693+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f70-6be0-8000-05753a2f578c'}}, tasks=(PregelTask(id='f4afa97e-dfcf-d260-47af-cad9e0dfe45e', name='node_b', path=('__pregel_pull', 'node_b'), error=None, interrupts=(), state=None, result={'foo': 'b', 'bar': ['b']}),), interrupts=()),\n",
       " StateSnapshot(values={'foo': '', 'bar': []}, next=('node_a',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f70-6be0-8000-05753a2f578c'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-08-07T06:06:04.603696+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f6b-6df0-bfff-6850366c68c1'}}, tasks=(PregelTask(id='49a3f65c-5d84-c7c1-0246-6d267376a399', name='node_a', path=('__pregel_pull', 'node_a'), error=None, interrupts=(), state=None, result={'foo': 'a', 'bar': ['a']}),), interrupts=()),\n",
       " StateSnapshot(values={'bar': []}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f6b-6df0-bfff-6850366c68c1'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-08-07T06:06:04.601700+00:00', parent_config=None, tasks=(PregelTask(id='a972c17a-16b1-2014-e18d-949bb8d60bd1', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'foo': ''}),), interrupts=())]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(graph.get_state_history(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a3d9a4",
   "metadata": {},
   "source": [
    "### Replay with threadId and checkpointId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7f9f16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'foo': 'b', 'bar': ['a', 'b']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f073549-9f70-6be0-8000-05753a2f578c\"}}\n",
    "graph.invoke(None, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec5eca32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'foo': 'b', 'bar': ['a', 'b']}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073559-651f-6663-8002-d40f0614cf3a'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-08-07T06:13:07.985366+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073559-651a-682e-8001-d392982ce672'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'foo': 'a', 'bar': ['a']}, next=('node_b',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073559-651a-682e-8001-d392982ce672'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-08-07T06:13:07.983364+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f70-6be0-8000-05753a2f578c'}}, tasks=(PregelTask(id='12e2e2d0-8f2f-9373-0abd-1161caa9dc4c', name='node_b', path=('__pregel_pull', 'node_b'), error=None, interrupts=(), state=None, result={'foo': 'b', 'bar': ['b']}),), interrupts=()),\n",
       " StateSnapshot(values={'foo': 'b', 'bar': ['a', 'b']}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f7a-6815-8002-69d9a10b72c8'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-08-07T06:06:04.607694+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f75-69e8-8001-cce7a15196a1'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'foo': 'a', 'bar': ['a']}, next=('node_b',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f75-69e8-8001-cce7a15196a1'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-08-07T06:06:04.605693+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f70-6be0-8000-05753a2f578c'}}, tasks=(PregelTask(id='f4afa97e-dfcf-d260-47af-cad9e0dfe45e', name='node_b', path=('__pregel_pull', 'node_b'), error=None, interrupts=(), state=None, result={'foo': 'b', 'bar': ['b']}),), interrupts=()),\n",
       " StateSnapshot(values={'foo': '', 'bar': []}, next=('node_a',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f70-6be0-8000-05753a2f578c'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-08-07T06:06:04.603696+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f6b-6df0-bfff-6850366c68c1'}}, tasks=(PregelTask(id='49a3f65c-5d84-c7c1-0246-6d267376a399', name='node_a', path=('__pregel_pull', 'node_a'), error=None, interrupts=(), state=None, result={'foo': 'a', 'bar': ['a']}),), interrupts=()),\n",
       " StateSnapshot(values={'bar': []}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f6b-6df0-bfff-6850366c68c1'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-08-07T06:06:04.601700+00:00', parent_config=None, tasks=(PregelTask(id='a972c17a-16b1-2014-e18d-949bb8d60bd1', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'foo': ''}),), interrupts=())]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(graph.get_state_history({\"thread_id\": \"1\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d3dba1",
   "metadata": {},
   "source": [
    "### Update state manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0d5a80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f073565-b899-62a0-8003-69bff56ce72b'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph.update_state(config, {\"foo\": 2, \"bar\": [\"b\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab4cc3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'foo': 2, 'bar': ['a', 'b', 'b']}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073565-b899-62a0-8003-69bff56ce72b'}}, metadata={'source': 'update', 'step': 3, 'parents': {}}, created_at='2025-08-07T06:18:38.860969+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073559-651f-6663-8002-d40f0614cf3a'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'foo': 'b', 'bar': ['a', 'b']}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073559-651f-6663-8002-d40f0614cf3a'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-08-07T06:13:07.985366+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073559-651a-682e-8001-d392982ce672'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'foo': 'a', 'bar': ['a']}, next=('node_b',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073559-651a-682e-8001-d392982ce672'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-08-07T06:13:07.983364+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f70-6be0-8000-05753a2f578c'}}, tasks=(PregelTask(id='12e2e2d0-8f2f-9373-0abd-1161caa9dc4c', name='node_b', path=('__pregel_pull', 'node_b'), error=None, interrupts=(), state=None, result={'foo': 'b', 'bar': ['b']}),), interrupts=()),\n",
       " StateSnapshot(values={'foo': 'b', 'bar': ['a', 'b']}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f7a-6815-8002-69d9a10b72c8'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-08-07T06:06:04.607694+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f75-69e8-8001-cce7a15196a1'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'foo': 'a', 'bar': ['a']}, next=('node_b',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f75-69e8-8001-cce7a15196a1'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-08-07T06:06:04.605693+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f70-6be0-8000-05753a2f578c'}}, tasks=(PregelTask(id='f4afa97e-dfcf-d260-47af-cad9e0dfe45e', name='node_b', path=('__pregel_pull', 'node_b'), error=None, interrupts=(), state=None, result={'foo': 'b', 'bar': ['b']}),), interrupts=()),\n",
       " StateSnapshot(values={'foo': '', 'bar': []}, next=('node_a',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f70-6be0-8000-05753a2f578c'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-08-07T06:06:04.603696+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f6b-6df0-bfff-6850366c68c1'}}, tasks=(PregelTask(id='49a3f65c-5d84-c7c1-0246-6d267376a399', name='node_a', path=('__pregel_pull', 'node_a'), error=None, interrupts=(), state=None, result={'foo': 'a', 'bar': ['a']}),), interrupts=()),\n",
       " StateSnapshot(values={'bar': []}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f073549-9f6b-6df0-bfff-6850366c68c1'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-08-07T06:06:04.601700+00:00', parent_config=None, tasks=(PregelTask(id='a972c17a-16b1-2014-e18d-949bb8d60bd1', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'foo': ''}),), interrupts=())]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(graph.get_state_history({\"thread_id\": \"1\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4084e571",
   "metadata": {},
   "source": [
    "## Memory store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d034116d",
   "metadata": {},
   "source": [
    "If you have a requirement to share data across chat threads. You need to use the store to save them in a node and get them later in another node\n",
    "\n",
    "Data in store grouped by namespace. Namespace is a tuple of the string list "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d381a4",
   "metadata": {},
   "source": [
    "## Basic usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "997599ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "in_memory_store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59710948",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fff2e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "memory_id = str(uuid.uuid4())\n",
    "memory = {\"food_preference\" : \"I like pizza\"}\n",
    "in_memory_store.put(namespace_for_memory, memory_id, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e73f348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Item(namespace=['1', 'memories'], key='8ef1dcdf-de95-47f5-882d-03e5cd4a5e84', value={'food_preference': 'I like pizza'}, created_at='2025-08-07T06:26:36.953355+00:00', updated_at='2025-08-07T06:26:36.953355+00:00', score=None)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories = in_memory_store.search(namespace_for_memory)\n",
    "memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f481746a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['1', 'memories'],\n",
       " 'key': '8ef1dcdf-de95-47f5-882d-03e5cd4a5e84',\n",
       " 'value': {'food_preference': 'I like pizza'},\n",
       " 'created_at': '2025-08-07T06:26:36.953355+00:00',\n",
       " 'updated_at': '2025-08-07T06:26:36.953355+00:00'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = in_memory_store.get(namespace_for_memory, memory_id)\n",
    "item.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1f93f4",
   "metadata": {},
   "source": [
    "### Semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f49ebb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import init_embeddings\n",
    "\n",
    "store = InMemoryStore(\n",
    "    index={\n",
    "        \"embed\": init_embeddings(\"openai:text-embedding-3-small\"),  # Embedding provider\n",
    "        \"dims\": 1536,                              # Embedding dimensions\n",
    "        \"fields\": [\"food_preference\", \"$\"]              # Fields to embed\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf56e103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find memories about food preferences\n",
    "# (This can be done after putting memories into the store)\n",
    "memories = store.search(\n",
    "    namespace_for_memory,\n",
    "    query=\"What does the user like to eat?\",\n",
    "    limit=3  # Return top 3 matches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cfcb212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bd08f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store with specific fields to embed\n",
    "store.put(\n",
    "    namespace_for_memory,\n",
    "    str(uuid.uuid4()),\n",
    "    {\n",
    "        \"food_preference\": \"I love Italian cuisine\",\n",
    "        \"context\": \"Discussing dinner plans\"\n",
    "    },\n",
    "    index=[\"food_preference\"]  # Only embed \"food_preferences\" field\n",
    ")\n",
    "\n",
    "# Store without embedding (still retrievable, but not searchable)\n",
    "store.put(\n",
    "    namespace_for_memory,\n",
    "    str(uuid.uuid4()),\n",
    "    {\"system_info\": \"Last updated: 2024-01-01\"},\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04b2cdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Item(namespace=['1', 'memories'], key='7f59ad29-ca2c-4860-b0d6-a5aaf97b1f0f', value={'food_preference': 'I love Italian cuisine', 'context': 'Discussing dinner plans'}, created_at='2025-08-07T06:31:22.934199+00:00', updated_at='2025-08-07T06:31:22.934199+00:00', score=0.9999992864789465),\n",
       " Item(namespace=['1', 'memories'], key='ef1793ac-d361-47bd-abe2-00a6661a4efc', value={'system_info': 'Last updated: 2024-01-01'}, created_at='2025-08-07T06:31:22.934199+00:00', updated_at='2025-08-07T06:31:22.934199+00:00', score=None)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find memories about food preferences\n",
    "# (This can be done after putting memories into the store)\n",
    "memories = store.search(\n",
    "    namespace_for_memory,\n",
    "    query=\"I love Italian cuisine\",\n",
    "    limit=3  # Return top 3 matches\n",
    ")\n",
    "memories   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f159e2da",
   "metadata": {},
   "source": [
    "### Use in LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa0f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "159287e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.config import RunnableConfig\n",
    "from langgraph.graph import MessagesState\n",
    "import uuid\n",
    "\n",
    "def update_memory(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "\n",
    "    # Get the user id from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Namespace the memory\n",
    "    namespace = (user_id, \"user_profile\")\n",
    "\n",
    "    # ... Analyze conversation and create a new memory\n",
    "\n",
    "    # Create a new memory ID\n",
    "    memory_id = str(uuid.uuid4())\n",
    "\n",
    "    # We create a new memory\n",
    "    store.put(namespace, memory_id, {\"username\": \"dtt\", \"full_name\": \"Dinh Trung Thao\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83e09fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.config import RunnableConfig\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "def get_memory(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "    # Get the user id from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Namespace the memory\n",
    "    namespace = (user_id, \"user_profile\")\n",
    "    \n",
    "    # We create a new memory\n",
    "    userprofile = store.search(namespace, query={\"username\": \"dtt\", \"full_name\": \"Dinh Trung Thao\"})\n",
    "    print(userprofile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0450c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from operator import add\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: str\n",
    "    bar: Annotated[list[str], add]\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(update_memory)\n",
    "workflow.add_node(get_memory)\n",
    "workflow.add_edge(START, \"update_memory\")\n",
    "workflow.add_edge(\"update_memory\", \"get_memory\")\n",
    "workflow.add_edge(\"get_memory\", END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "in_memory_store = InMemoryStore()\n",
    "graph = workflow.compile(checkpointer=checkpointer, store=in_memory_store)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66ed1232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'update_memory': None}\n",
      "[Item(namespace=['1', 'user_profile'], key='40e54d49-0a01-48ab-b56c-eab5b4e7cf9c', value={'username': 'dtt', 'full_name': 'Dinh Trung Thao'}, created_at='2025-08-07T07:00:29.576125+00:00', updated_at='2025-08-07T07:00:29.576125+00:00', score=None)]\n",
      "{'get_memory': None}\n"
     ]
    }
   ],
   "source": [
    "# Invoke the graph\n",
    "user_id = \"1\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": user_id}}\n",
    "\n",
    "# First let's just say hi to the AI\n",
    "for update in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Hello store\"}]}, config, stream_mode=\"updates\"\n",
    "):\n",
    "    print(update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf01b8d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_GeneratorContextManager' object has no attribute 'get_next_version'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfoo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trung Thao\\Documents\\GitHub\\data-science\\ai_engineer\\LangGraph\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3008\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   3005\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3006\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3008\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3010\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3011\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3012\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3013\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3014\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3015\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3016\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3017\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3018\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3019\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3020\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3021\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3022\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trung Thao\\Documents\\GitHub\\data-science\\ai_engineer\\LangGraph\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2579\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2571\u001b[39m     config[CONF][CONFIG_KEY_DURABILITY] = durability_\n\u001b[32m   2573\u001b[39m config[CONF][CONFIG_KEY_RUNTIME] = Runtime(\n\u001b[32m   2574\u001b[39m     context=context,\n\u001b[32m   2575\u001b[39m     store=store,\n\u001b[32m   2576\u001b[39m     stream_writer=stream_writer,\n\u001b[32m   2577\u001b[39m     previous=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2578\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2579\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mSyncPregelLoop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2580\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2581\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStreamProtocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_modes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2582\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2583\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2584\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2585\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2586\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2587\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspecs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2588\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2589\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_channels_asis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2591\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2592\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmigrate_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_migrate_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m loop:\n\u001b[32m   2600\u001b[39m     \u001b[38;5;66;03m# create runner\u001b[39;00m\n\u001b[32m   2601\u001b[39m     runner = PregelRunner(\n\u001b[32m   2602\u001b[39m         submit=config[CONF].get(\n\u001b[32m   2603\u001b[39m             CONFIG_KEY_RUNNER_SUBMIT, weakref.WeakMethod(loop.submit)\n\u001b[32m   (...)\u001b[39m\u001b[32m   2606\u001b[39m         node_finished=config[CONF].get(CONFIG_KEY_NODE_FINISHED),\n\u001b[32m   2607\u001b[39m     )\n\u001b[32m   2608\u001b[39m     \u001b[38;5;66;03m# enable subgraph streaming\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Trung Thao\\Documents\\GitHub\\data-science\\ai_engineer\\LangGraph\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_loop.py:929\u001b[39m, in \u001b[36mSyncPregelLoop.__init__\u001b[39m\u001b[34m(self, input, stream, config, store, cache, checkpointer, nodes, specs, trigger_to_nodes, durability, manager, interrupt_after, interrupt_before, input_keys, output_keys, stream_keys, migrate_checkpoint, retry_policy, cache_policy)\u001b[39m\n\u001b[32m    927\u001b[39m \u001b[38;5;28mself\u001b[39m.stack = ExitStack()\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m checkpointer:\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m     \u001b[38;5;28mself\u001b[39m.checkpointer_get_next_version = \u001b[43mcheckpointer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_next_version\u001b[49m\n\u001b[32m    930\u001b[39m     \u001b[38;5;28mself\u001b[39m.checkpointer_put_writes = checkpointer.put_writes\n\u001b[32m    931\u001b[39m     \u001b[38;5;28mself\u001b[39m.checkpointer_put_writes_accepts_task_path = (\n\u001b[32m    932\u001b[39m         signature(checkpointer.put_writes).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mtask_path\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    933\u001b[39m         \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    934\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: '_GeneratorContextManager' object has no attribute 'get_next_version'"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph.invoke({\"foo\": \"\"}, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
