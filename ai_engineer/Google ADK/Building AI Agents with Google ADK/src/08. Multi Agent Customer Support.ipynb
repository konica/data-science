{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae70f448-f79e-416c-9bfa-ee7800531a12",
   "metadata": {},
   "source": [
    "# It takes a village: Multi-agent customer support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73104146-82e2-4635-b958-0f3db0d9ccfc",
   "metadata": {},
   "source": [
    "### üåê Creating a Root Agent with Sub-Agents \n",
    "\n",
    "With multi-agents, each agent can specialize in a certain role, with a coordinator delegating tasks to the appropriate specialist. \n",
    "\n",
    "In our customer support example, imagine we want a more robust support assistant. We could break it into:\n",
    "\n",
    "- üëã A **Greeting Agent**, handling greetings.\n",
    "- üîë An **Account Agent**, handling account access issues.\n",
    "- ‚ùì An **FAQ Agent**, using a pre-defined list of FAQs to answer common customer questions.\n",
    "- üß≠ A **Root Agent (Coordinator)** that receives the user‚Äôs query and decides which of the other agents should handle it, or handles it itself if it doesn‚Äôt fit any specialized category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef0d070-8aba-44b4-9e1e-7449ae9975a1",
   "metadata": {},
   "source": [
    "## ‚ùóÔ∏è Note: Run the **hidden cells** below to initialize the agent, before running the rest of the code. ‚ùóÔ∏è "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf9ba90f-a906-4fe5-9ba9-1500c665c9f0",
   "metadata": {
    "collapsed": false,
    "executionCancelledAt": null,
    "executionTime": 54,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "lastExecutedAt": 1754098040594,
    "lastExecutedByKernel": "6be806b1-3b3c-4450-8abe-19f288dae7e0",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import importlib\nimportlib.invalidate_caches()"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.invalidate_caches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86663ea1-9f31-42dd-8ffa-60748cce7526",
   "metadata": {
    "collapsed": false,
    "executionCancelledAt": null,
    "executionTime": 48,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "lastExecutedAt": 1754098040642,
    "lastExecutedByKernel": "6be806b1-3b3c-4450-8abe-19f288dae7e0",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import os\nfrom google.adk.agents import LlmAgent\nfrom google.adk.tools import FunctionTool\nfrom google import genai\nfrom google.adk.models.lite_llm import LiteLlm\nimport litellm\nimport os\n\nos.environ[\"OPENAI_API_BASE\"]=\"http://localhost:11434/v1\"\n\nAGENT_MODEL = LiteLlm(model=\"openai/gpt-4o-mini\")"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deprecated in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\google adk\\.venv\\lib\\site-packages (1.2.18)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\trung thao\\documents\\github\\data-science\\ai_engineer\\google adk\\.venv\\lib\\site-packages (from deprecated) (1.17.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install deprecated\n",
    "\n",
    "import os\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.tools import FunctionTool\n",
    "from google import genai\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "import litellm\n",
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_BASE\"]=\"http://localhost:11434/v1\"\n",
    "\n",
    "AGENT_MODEL = LiteLlm(model=\"openai/gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9cc29f4-3689-4c35-a146-dd31a88088c2",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1754098040690,
    "lastExecutedByKernel": "6be806b1-3b3c-4450-8abe-19f288dae7e0",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Install and import required libraries\nimport nest_asyncio\nimport asyncio\nnest_asyncio.apply()  # Required for async in notebooks\n\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.genai import types\n\n# Constants ‚Äî define application, user, and session identifiers\nAPP_NAME      = \"adk_course_app\"\nUSER_ID       = \"user_123\"\nSESSION_ID    = \"support_session\""
   },
   "outputs": [],
   "source": [
    "# Install and import required libraries\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "nest_asyncio.apply()  # Required for async in notebooks\n",
    "\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types\n",
    "\n",
    "# Constants ‚Äî define application, user, and session identifiers\n",
    "APP_NAME      = \"adk_course_app\"\n",
    "USER_ID       = \"user_123\"\n",
    "SESSION_ID    = \"support_session\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e95adf8e-8cde-4cbb-8a1e-56bfd9bf0c0d",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 51,
    "lastExecutedAt": 1754098040742,
    "lastExecutedByKernel": "6be806b1-3b3c-4450-8abe-19f288dae7e0",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# FAQ knowledge base & tool \nFAQ_DATA = {\n    \"return policy\": \"You can return items within 30 days of purchase.\",\n    \"hours\": \"Our support team is available from 9 am to 5 pm, Monday to Friday.\",\n    \"contact\": \"You can reach support at help@example.com.\"\n}\n\ndef lookup_faq(question: str) -> str:\n    faq_text = \"\\n\".join(f\"- {k}: {v}\" for k, v in FAQ_DATA.items())\n    prompt = (\n        f\"You are a helpful assistant. Here is a list of FAQs:\\n\\n{faq_text}\\n\\n\"\n        f\"User question: \\\"{question}\\\". \"\n        f\"Reply with the best match or say you don't know.\"\n    )\n    response = litellm.completion(\n        model=\"gpt-4o-mini\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n\nfaq_tool  = FunctionTool(func=lookup_faq)"
   },
   "outputs": [],
   "source": [
    "# FAQ knowledge base & tool \n",
    "FAQ_DATA = {\n",
    "    \"return policy\": \"You can return items within 30 days of purchase.\",\n",
    "    \"hours\": \"Our support team is available from 9 am to 5 pm, Monday to Friday.\",\n",
    "    \"contact\": \"You can reach support at help@example.com.\"\n",
    "}\n",
    "\n",
    "def lookup_faq(question: str) -> str:\n",
    "    faq_text = \"\\n\".join(f\"- {k}: {v}\" for k, v in FAQ_DATA.items())\n",
    "    prompt = (\n",
    "        f\"You are a helpful assistant. Here is a list of FAQs:\\n\\n{faq_text}\\n\\n\"\n",
    "        f\"User question: \\\"{question}\\\". \"\n",
    "        f\"Reply with the best match or say you don't know.\"\n",
    "    )\n",
    "    response = litellm.completion(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "faq_tool  = FunctionTool(func=lookup_faq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b38c8a85-0457-49bb-9a71-383d98316334",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 51,
    "lastExecutedAt": 1754098040794,
    "lastExecutedByKernel": "6be806b1-3b3c-4450-8abe-19f288dae7e0",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Specialist Agents\ngreeting_agent = LlmAgent(\n    name=\"GreetingAgent\",\n    description=\"Handles greetings from users.\",\n    instruction=\"Respond cheerfully when the user says hello.\",\n    model=AGENT_MODEL\n)\n\naccount_agent = LlmAgent(\n    name=\"AccountAgent\",\n    description=\"Handles questions about login issues or account access.\",\n    instruction=\"Help users who are having trouble logging in or accessing their account.\",\n    model=AGENT_MODEL\n)\n\nfaq_agent = LlmAgent(\n    name=\"FAQAgent\",\n    description=\"Answers common questions using the FAQ knowledge base.\",\n    instruction=\"Use the FAQ tool to answer questions that match the FAQs.\",\n    model=AGENT_MODEL,\n    tools=[faq_tool]\n)\n\n# Root agent with delegation logic\nroot_agent = LlmAgent(\n    name=\"SupportRootAgent\",\n    description=\"Delegates to specialized sub-agents for support queries.\",\n    instruction=(\n        \"If the user greets you, delegate to GreetingAgent.\\n\"\n        \"If the user has an account or login issue, delegate to AccountAgent.\\n\"\n        \"If the question matches a known FAQ topic (e.g., returns, hours, contact), \"\n        \"delegate to FAQAgent. Do not answer as the FAQAgent if the topic doesn't match any of the FAQs.\\n\"\n        \"Otherwise, answer directly as best you (the Root Agent) can.\"\n    ),\n    model=AGENT_MODEL,\n    sub_agents=[greeting_agent, account_agent, faq_agent]\n)"
   },
   "outputs": [],
   "source": [
    "# Specialist Agents\n",
    "greeting_agent = LlmAgent(\n",
    "    name=\"GreetingAgent\",\n",
    "    description=\"Handles greetings from users.\",\n",
    "    instruction=\"Respond cheerfully when the user says hello.\",\n",
    "    model=AGENT_MODEL\n",
    ")\n",
    "\n",
    "account_agent = LlmAgent(\n",
    "    name=\"AccountAgent\",\n",
    "    description=\"Handles questions about login issues or account access.\",\n",
    "    instruction=\"Help users who are having trouble logging in or accessing their account.\",\n",
    "    model=AGENT_MODEL\n",
    ")\n",
    "\n",
    "faq_agent = LlmAgent(\n",
    "    name=\"FAQAgent\",\n",
    "    description=\"Answers common questions using the FAQ knowledge base.\",\n",
    "    instruction=\"Use the FAQ tool to answer questions that match the FAQs.\",\n",
    "    model=AGENT_MODEL,\n",
    "    tools=[faq_tool]\n",
    ")\n",
    "\n",
    "# Root agent with delegation logic\n",
    "root_agent = LlmAgent(\n",
    "    name=\"SupportRootAgent\",\n",
    "    description=\"Delegates to specialized sub-agents for support queries.\",\n",
    "    instruction=(\n",
    "        \"If the user greets you, delegate to GreetingAgent.\\n\"\n",
    "        \"If the user has an account or login issue, delegate to AccountAgent.\\n\"\n",
    "        \"If the question matches a known FAQ topic (e.g., returns, hours, contact), \"\n",
    "        \"delegate to FAQAgent. Do not answer as the FAQAgent if the topic doesn't match any of the FAQs.\\n\"\n",
    "        \"Otherwise, answer directly as best you (the Root Agent) can.\"\n",
    "    ),\n",
    "    model=AGENT_MODEL,\n",
    "    sub_agents=[greeting_agent, account_agent, faq_agent]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0d24b50-1873-47f0-af18-39ae54ce4d9f",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 332,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: Hello!\n",
      "<<< Agent GreetingAgent's response: Hello there! üòä How can I assist you today?\n",
      "\n",
      ">>> User Query: I can't access my account.\n",
      "<<< Agent AccountAgent's response: I'm here to help you with accessing your account. Could you please provide more details about the issue you're experiencing?\n",
      "\n",
      ">>> User Query: What is your return policy?\n",
      "<<< Agent FAQAgent's response: Our return policy allows you to return items within 30 days of purchase.\n",
      "\n",
      ">>> User Query: I have a privacy question.\n",
      "<<< Agent SupportRootAgent's response: I'm unable to transfer to a specialized agent for privacy questions. You can ask me directly, and I'll do my best to help you! What specific privacy question do you have?\n"
     ]
    }
   ],
   "source": [
    "# Session & runner \n",
    "session_service = InMemorySessionService()\n",
    "await session_service.create_session(app_name=APP_NAME, user_id=USER_ID,\n",
    "                               session_id=SESSION_ID)\n",
    "\n",
    "runner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)\n",
    "\n",
    "# Function to chat with the root agent\n",
    "async def call_agent_async(query: str):\n",
    "    print(f\"\\n>>> User Query: {query}\")\n",
    "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "    final_response = \"Agent did not produce a final response.\"\n",
    "\n",
    "    async for event in runner.run_async(user_id=USER_ID,\n",
    "                                        session_id=SESSION_ID,\n",
    "                                        new_message=content):\n",
    "        if event.is_final_response():\n",
    "            if event.content and event.content.parts:\n",
    "                final_response = event.content.parts[0].text\n",
    "            break\n",
    "\n",
    "    print(f\"<<< Agent {event.author}'s response: {final_response}\")\n",
    "\n",
    "# Test the full system\n",
    "await call_agent_async(\"Hello!\")                       # GreetingAgent\n",
    "await call_agent_async(\"I can't access my account.\")   # AccountAgent\n",
    "await call_agent_async(\"What is your return policy?\")  # FAQAgent\n",
    "await call_agent_async(\"I have a privacy question.\")   # SupportRootAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd4a13-7f70-4c6c-8eb6-e2916c827aae",
   "metadata": {},
   "source": [
    "After running the queries, we can observe how our agents collaborated to best address the queries. We have now built a mini multi-agent system using Google ADK! üéâ"
   ]
  }
 ],
 "metadata": {
  "editor": "DataLab",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
