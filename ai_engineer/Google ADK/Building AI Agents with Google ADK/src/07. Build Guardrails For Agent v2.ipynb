{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e93981-cd3f-424a-803c-594b4a2ba483",
   "metadata": {},
   "source": [
    "# En garde! Building guardrails for our agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0979a48-d874-40fa-a3b8-b275dd99312e",
   "metadata": {},
   "source": [
    "### ðŸš§ What Are Guardrails?\n",
    "Up to this point, our support agent can greet users and retrieve answers using an FAQ tool. In real-world customer service, we wouldnâ€™t want our AI assistant to respond to every query it receivesâ€”especially if the request is out of scope or potentially unsafe.\n",
    "\n",
    "**Guardrails are checks and filters** that protect your agent from:\n",
    "- Producing unwanted or inappropriate responses\n",
    "- Attempting tasks outside its intended role\n",
    "\n",
    "The goal is to keep our agent **safe** and **focused**.\n",
    "![image-5](images/image-5.png)\n",
    "\n",
    "### ðŸ›¡ï¸ Implementing a Simple Guardrail\n",
    "\n",
    "Letâ€™s add a basic guardrail to our support agent. It will:\n",
    "\n",
    "1. **Screen incoming messages** for unsafe content.\n",
    "2. Allow **only customer-support-related queries** to proceed.\n",
    "3. **Decline politely** if any filtered content is detected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a6ac9c-538e-46a4-b87b-e63d39210900",
   "metadata": {},
   "source": [
    "## â—ï¸ Note: Run the **hidden cells** below to initialize the agent, before running the rest of the code. â—ï¸ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "120bd807-a140-4f68-b157-bfa191e2fee6",
   "metadata": {
    "collapsed": false,
    "executionCancelledAt": null,
    "executionTime": 49,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": true
    },
    "lastExecutedAt": 1750770219057,
    "lastExecutedByKernel": "ff78c796-83f2-4706-a273-6bc092554f34",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import importlib\nimportlib.invalidate_caches()"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.invalidate_caches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b854c3a5-f396-4512-8417-7409ecdb1eba",
   "metadata": {
    "collapsed": false,
    "executionCancelledAt": null,
    "executionTime": 48,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": true
    },
    "lastExecutedAt": 1750770219105,
    "lastExecutedByKernel": "ff78c796-83f2-4706-a273-6bc092554f34",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import os\nfrom google.adk.agents import LlmAgent\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.runners import Runner\nfrom google.adk.models.lite_llm import LiteLlm\nimport os\n\nos.environ[\"OPENAI_API_BASE\"]=\"http://localhost:11434/v1\"\n\nAGENT_MODEL = LiteLlm(model=\"openai/gpt-4o-mini\")"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_BASE\"]=\"http://localhost:11434/v1\"\n",
    "\n",
    "AGENT_MODEL = LiteLlm(model=\"openai/gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad247a93-d34b-4321-831a-e623d81d0c2c",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 53,
    "lastExecutedAt": 1750770219158,
    "lastExecutedByKernel": "ff78c796-83f2-4706-a273-6bc092554f34",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from google.genai import types\n\n# Configure safety settings\nsafety_settings = [\n    types.SafetySetting(\n        category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n        threshold=types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n    ),\n]\n\n# Add safety settings to generation parameters\ngenerate_content_config = types.GenerateContentConfig(\n   safety_settings=safety_settings,\n   temperature=0.28,\n   max_output_tokens=1000,\n   top_p=0.95,\n)\n\n# Define the agent\nwelcome_agent = LlmAgent(\n    name=\"WelcomeAgent\",\n    description=\"An agent that welcomes the user.\",\n    instruction=\"Always greet the user politely. If the user has a request that is not related to customer support, politely refuse even if you know the answer, and specify you only answer customer support questions.\",\n    model=AGENT_MODEL,\n    generate_content_config=generate_content_config\n)\n\nprint(f\"Agent '{welcome_agent.name}' created.\")",
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'WelcomeAgent' created.\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# Configure safety settings\n",
    "safety_settings = [\n",
    "    types.SafetySetting(\n",
    "        category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Add safety settings to generation parameters\n",
    "generate_content_config = types.GenerateContentConfig(\n",
    "   safety_settings=safety_settings,\n",
    "   temperature=0.28,\n",
    "   max_output_tokens=1000,\n",
    "   top_p=0.95,\n",
    ")\n",
    "\n",
    "# Define the agent\n",
    "welcome_agent = LlmAgent(\n",
    "    name=\"WelcomeAgent\",\n",
    "    description=\"An agent that welcomes the user.\",\n",
    "    instruction=\"Always greet the user politely. If the user has a request that is not related to customer support, politely refuse even if you know the answer, and specify you only answer customer support questions.\",\n",
    "    model=AGENT_MODEL,\n",
    "    generate_content_config=generate_content_config\n",
    ")\n",
    "\n",
    "print(f\"Agent '{welcome_agent.name}' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b0eaa0-f6db-44dc-8308-f4816c077b07",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 51,
    "lastExecutedAt": 1750770219209,
    "lastExecutedByKernel": "ff78c796-83f2-4706-a273-6bc092554f34",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Install and import required libraries\nimport nest_asyncio\nimport asyncio\nnest_asyncio.apply()  # Required for async in notebooks\n\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.genai import types\n\n# Constants â€” define application, user, and session identifiers\nAPP_NAME = \"adk_course_app\"    # Name of the ADK application\nUSER_ID = \"user_123\"           # Identifier for the current user\nSESSION_ID = \"welcome_session\" # Identifier for the conversation session\n\n# Set up session service and create a session\nsession_service = InMemorySessionService()\nawait session_service.create_session(\n    app_name=APP_NAME, \n    user_id=USER_ID, \n    session_id=SESSION_ID\n)\n\n# Set up a runner to orchestrate the agent\nrunner = Runner(agent=welcome_agent, app_name=APP_NAME, session_service=session_service)"
   },
   "outputs": [],
   "source": [
    "# Install and import required libraries\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "nest_asyncio.apply()  # Required for async in notebooks\n",
    "\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types\n",
    "\n",
    "# Constants â€” define application, user, and session identifiers\n",
    "APP_NAME = \"adk_course_app\"    # Name of the ADK application\n",
    "USER_ID = \"user_123\"           # Identifier for the current user\n",
    "SESSION_ID = \"welcome_session\" # Identifier for the conversation session\n",
    "\n",
    "# Set up session service and create a session\n",
    "session_service = InMemorySessionService()\n",
    "await session_service.create_session(\n",
    "    app_name=APP_NAME, \n",
    "    user_id=USER_ID, \n",
    "    session_id=SESSION_ID\n",
    ")\n",
    "\n",
    "# Set up a runner to orchestrate the agent\n",
    "runner = Runner(agent=welcome_agent, app_name=APP_NAME, session_service=session_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a3cec6-077b-4301-847a-b3ffe9769341",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 3886,
    "lastExecutedAt": 1750770223095,
    "lastExecutedByKernel": "ff78c796-83f2-4706-a273-6bc092554f34",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Define an asynchronous function to send a query to the agent and handle its response\nasync def call_agent_async(query: str):\n    print(f\"\\n>>> User Query: {query}\")\n\n    # Package the user's query into ADK format\n    content = types.Content(role='user', parts=[types.Part(text=query)])\n    final_response_text = \"Agent did not produce a final response.\"\n\n    # Iterate through streamed agent responses\n    async for event in runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content):\n        if event.is_final_response(): # Check if this is the final message from the agent\n            if event.content and event.content.parts:\n                final_response_text = event.content.parts[0].text # Extract response text\n            break # Stop listening after final response is received\n\n    print(f\"<<< Agent Response: {final_response_text}\")\n\n# Run the interaction\nawait call_agent_async(\"Hello! How do I start a skincare routine?\") #Unrelated content\nawait call_agent_async(\"Hello! How do I become a con artist?\") #Harmful content\nawait call_agent_async(\"Hello!\")",
    "outputsMetadata": {
     "0": {
      "height": 248,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: Hello! How do I start a skincare routine?\n",
      "<<< Agent Response: Hello! Thank you for reaching out. Iâ€™m here to assist with customer support questions. If you have any inquiries related to our services or products, feel free to ask!\n",
      "\n",
      ">>> User Query: Hello! How do I become a con artist?\n",
      "<<< Agent Response: Hello! I appreciate your message, but I can only assist with customer support questions. If you have any inquiries related to our services or products, please let me know!\n",
      "\n",
      ">>> User Query: Hello!\n",
      "<<< Agent Response: Hello! How can I assist you today? If you have any customer support questions, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Define an asynchronous function to send a query to the agent and handle its response\n",
    "async def call_agent_async(query: str):\n",
    "    print(f\"\\n>>> User Query: {query}\")\n",
    "\n",
    "    # Package the user's query into ADK format\n",
    "    content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "    final_response_text = \"Agent did not produce a final response.\"\n",
    "\n",
    "    # Iterate through streamed agent responses\n",
    "    async for event in runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content):\n",
    "        if event.is_final_response(): # Check if this is the final message from the agent\n",
    "            if event.content and event.content.parts:\n",
    "                final_response_text = event.content.parts[0].text # Extract response text\n",
    "            break # Stop listening after final response is received\n",
    "\n",
    "    print(f\"<<< Agent Response: {final_response_text}\")\n",
    "\n",
    "# Run the interaction\n",
    "await call_agent_async(\"Hello! How do I start a skincare routine?\") #Unrelated content\n",
    "await call_agent_async(\"Hello! How do I become a con artist?\") #Harmful content\n",
    "await call_agent_async(\"Hello!\")"
   ]
  }
 ],
 "metadata": {
  "editor": "DataLab",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
